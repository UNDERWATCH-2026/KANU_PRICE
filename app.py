import streamlit as st
import pandas as pd
import altair as alt
from supabase import create_client
from datetime import datetime, timedelta

# =========================
# 0ï¸âƒ£ ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="Capsule Price Intelligence", layout="wide")

# =========================
# 1ï¸âƒ£ Supabase ì„¤ì •
# =========================
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_ANON_KEY"]
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# =========================
# 2ï¸âƒ£ ë°ì´í„° ë¡œë”©
# =========================
@st.cache_data(ttl=300)
def load_product_summary():
    cols = [
        "product_url",
        "brand",
        "category1",
        "category2",
        "product_name",
        "current_unit_price",
        "is_discount",
        "first_seen_date",
        "last_seen_date",
        "event_count",
        "product_event_status",
        "is_new_product",
        "brew_type_kr",
    ]
    res = supabase.table("product_price_summary_enriched").select(", ".join(cols)).execute()
    return pd.DataFrame(res.data)

@st.cache_data(ttl=300)
def load_events(product_url: str):
    res = (
        supabase.table("product_all_events")
        .select("date, unit_price, event_type")
        .eq("product_url", product_url)
        .order("date", desc=True)
        .execute()
    )
    return pd.DataFrame(res.data)

@st.cache_data(ttl=300)
def load_lifecycle_events(product_url: str):
    res = (
        supabase.table("product_lifecycle_events")
        .select("date, lifecycle_event")
        .eq("product_url", product_url)
        .order("date", desc=True)
        .execute()
    )
    return pd.DataFrame(res.data)

# =========================
# 2-1ï¸âƒ£ ì§ˆë¬¸ ë¡œê·¸ ì €ì¥
# =========================
def save_question_log(question: str, q_type: str, used_llm: bool, answer: str = None, filters: dict = None):
    """
    ì§ˆë¬¸ ë¡œê·¸ë¥¼ Supabaseì— ì €ì¥
    
    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        q_type: ì§ˆë¬¸ íƒ€ì… (DISCOUNT, NEW, PRICE_MIN ë“±)
        used_llm: LLM ì‚¬ìš© ì—¬ë¶€
        answer: ìƒì„±ëœ ë‹µë³€ (ì„ íƒ)
        filters: ì ìš©ëœ í•„í„° ì •ë³´ (ì„ íƒ)
    """
    try:
        log_data = {
            "question_text": question,
            "question_type": q_type,
            "used_llm": used_llm,
            "created_at": datetime.now().isoformat()
        }
        
        # ë‹µë³€ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if answer:
            # ë‹µë³€ì´ dictì¸ ê²½ìš° í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if isinstance(answer, dict):
                log_data["answer_text"] = answer.get("text", str(answer))
                log_data["answer_type"] = answer.get("type", "unknown")
            else:
                log_data["answer_text"] = str(answer)
        
        # í•„í„° ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if filters:
            log_data["filters"] = filters
        
        supabase.table("question_logs").insert(log_data).execute()
    except Exception as e:
        print("ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨:", e)


# =========================
# 2-2ï¸âƒ£ ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# =========================

def normalize_brand_name(brand_query: str) -> str:
    """
    ë¸Œëœë“œëª…ì„ ì •ê·œí™”
    ì˜ˆ: 'ì¹´ëˆ„', 'ì¹´ëˆ„ë°”ë¦¬ìŠ¤íƒ€', 'ì¹´ëˆ„ ë°”ë¦¬ìŠ¤íƒ€' â†’ 'ì¹´ëˆ„ ë°”ë¦¬ìŠ¤íƒ€'
    """
    brand_query = brand_query.lower().strip()
    
    # ë¸Œëœë“œëª… ë§¤í•‘ (ê³µë°± ì œê±° ë²„ì „ â†’ ì •ì‹ ëª…ì¹­)
    brand_mapping = {
        "ì¹´ëˆ„": "ì¹´ëˆ„ ë°”ë¦¬ìŠ¤íƒ€",
        "ì¹´ëˆ„ë°”ë¦¬ìŠ¤íƒ€": "ì¹´ëˆ„ ë°”ë¦¬ìŠ¤íƒ€",
        "ì¹´ëˆ„ ë°”ë¦¬ìŠ¤íƒ€": "ì¹´ëˆ„ ë°”ë¦¬ìŠ¤íƒ€",
        "ë„¤ìŠ¤í”„ë ˆì†Œ": "ë„¤ìŠ¤í”„ë ˆì†Œ",
        "ìŠ¤íƒ€ë²…ìŠ¤": "ìŠ¤íƒ€ë²…ìŠ¤",
        "ì¼ë¦¬": "ì¼ë¦¬",
        "ëŒì²´êµ¬ìŠ¤í† ": "ëŒì²´êµ¬ìŠ¤í† ",
    }
    
    # ê³µë°± ì œê±°í•˜ì—¬ ë§¤ì¹­
    for key, value in brand_mapping.items():
        if key.replace(" ", "") == brand_query.replace(" ", ""):
            return value
    
    return brand_query

def extract_brand_from_question(q: str, df_all: pd.DataFrame) -> str:
    """ì§ˆë¬¸ì—ì„œ ë¸Œëœë“œëª… ì¶”ì¶œ"""
    q_lower = q.lower()
    brands = df_all["brand"].dropna().unique().tolist()
    
    for brand in brands:
        if brand and brand.lower() in q_lower:
            return brand
    
    # ì •ê·œí™”ëœ ë¸Œëœë“œëª…ìœ¼ë¡œ ì¬ì‹œë„
    for brand in brands:
        normalized = normalize_brand_name(q_lower)
        if brand.lower() == normalized.lower():
            return brand
    
    return None

def extract_product_name_from_question(q: str) -> str:
    """ì§ˆë¬¸ì—ì„œ ì œí’ˆëª… í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # í• ì¸, ê¸°ê°„ ë“±ì˜ í‚¤ì›Œë“œ ì œê±°
    exclude_words = ["í• ì¸", "ê¸°ê°„", "ì–¸ì œ", "ì–¼ë§ˆ", "ê°€ê²©", "ì œí’ˆ", "ë¸Œëœë“œ", "ì¹´ëˆ„", "ë°”ë¦¬ìŠ¤íƒ€"]
    
    words = q.split()
    product_keywords = []
    
    for word in words:
        if len(word) >= 2 and not any(ex in word for ex in exclude_words):
            product_keywords.append(word)
    
    return " ".join(product_keywords) if product_keywords else None

def classify_intent(q: str):
    q = q.lower()

    # ğŸ”¥ "í• ì¸ ê¸°ê°„" í‚¤ì›Œë“œ ê°ì§€
    if "í• ì¸" in q and ("ê¸°ê°„" in q or "ì–¸ì œ" in q):
        return "DISCOUNT_PERIOD"
    if "í• ì¸" in q or "í–‰ì‚¬" in q:
        return "DISCOUNT"
    if any(word in q for word in ["ì‹ ì œí’ˆ", "ìƒˆë¡­ê²Œ", "ìƒˆë¡œ", "ì‹ ê·œ", "ì¶œì‹œ", "ìƒˆë¡œìš´", "ì²˜ìŒ"]):
        return "NEW"
    if "ê°€ì¥ ì‹¼" in q or "ìµœì €ê°€" in q:
        return "PRICE_MIN"
    if "ë¹„ì‹¼" in q or "ìµœê³ ê°€" in q:
        return "PRICE_MAX"
    if any(word in q for word in ["ìƒìŠ¹", "ì¦ê°€"]) and "ì•Š" not in q:
        return "PRICE_UP"
    if "ë³€ë™" in q or "ë§ì´ ë°”ë€" in q:
        return "VOLATILITY"
    if "í’ˆì ˆ" in q:
        return "OUT"
    if "ë³µì›" in q:
        return "RESTORE"
    if "ì •ìƒê°€" in q and "ë³€ë™" in q:
        return "NORMAL_CHANGE"

    return "UNKNOWN"

def extract_period(q: str):
    today = datetime.today()

    if any(word in q for word in ["ìµœê·¼ 7ì¼", "ìµœê·¼ ì¼ì£¼ì¼", "ìµœê·¼ 1ì£¼ì¼"]):
        return today - timedelta(days=7)
    if any(word in q for word in ["ìµœê·¼ í•œ ë‹¬", "ìµœê·¼ 30ì¼", "ìµœê·¼ 1ê°œì›”"]):
        return today - timedelta(days=30)
    if "ìµœê·¼ 3ê°œì›”" in q:
        return today - timedelta(days=90)
    if "ìµœê·¼ 1ë…„" in q:
        return today - timedelta(days=365)

    return None

def extract_brew_type(q: str, df_all: pd.DataFrame):
    q = q.lower()
    brew_list = df_all["brew_type_kr"].dropna().unique().tolist()

    for brew in brew_list:
        if brew and brew.lower() in q:
            return brew
    return None

def execute_rule(intent, question, df_summary, date_from=None, date_to=None):
    df_work = df_summary.copy()

    brew_condition = extract_brew_type(question, df_summary)
    if brew_condition:
        df_work = df_work[df_work["brew_type_kr"] == brew_condition]

    # ğŸ”¥ ë¸Œëœë“œ í•„í„°ë§
    brand_from_q = extract_brand_from_question(question, df_summary)
    if brand_from_q:
        df_work = df_work[df_work["brand"] == brand_from_q]
    
    # ğŸ”¥ ì œí’ˆëª… í•„í„°ë§
    product_keywords = extract_product_name_from_question(question)
    if product_keywords:
        mask = False
        for keyword in product_keywords.split():
            if len(keyword) >= 2:
                mask |= df_work["product_name"].str.contains(keyword, case=False, na=False)
        if mask is not False:
            df_work = df_work[mask]

    start_date = extract_period(question)

    # ğŸ”¥ í• ì¸ ê¸°ê°„ ì¡°íšŒ
    if intent == "DISCOUNT_PERIOD":
        results = []
        
        for _, row in df_work.iterrows():
            # í• ì¸ ê¸°ê°„ ì¡°íšŒ
            res = supabase.rpc(
                "get_discount_periods_in_range",
                {
                    "p_product_url": row["product_url"],
                    "p_date_from": (date_from if date_from else datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d"),
                    "p_date_to": (date_to if date_to else datetime.now()).strftime("%Y-%m-%d"),
                }
            ).execute()
            
            discount_periods = res.data if res.data else []
            
            if discount_periods:
                for period in discount_periods:
                    # í• ì¸ ê¸°ê°„ì˜ ê°€ê²© ì¡°íšŒ
                    price_res = (
                        supabase.table("product_all_events")
                        .select("unit_price")
                        .eq("product_url", row["product_url"])
                        .eq("event_type", "DISCOUNT")
                        .gte("date", period["discount_start_date"])
                        .lte("date", period["discount_end_date"])
                        .limit(1)
                        .execute()
                    )
                    
                    discount_price = price_res.data[0]["unit_price"] if price_res.data else row["current_unit_price"]
                    
                    results.append({
                        "text": f"â€¢ **{row['brand']}** - {row['product_name']}\n"
                                f"  ğŸ“… í• ì¸ ê¸°ê°„: {period['discount_start_date']} ~ {period['discount_end_date']}\n"
                                f"  ğŸ’° í• ì¸ê°€: {float(discount_price):,.1f}ì›",
                        "product_name": row['product_name']
                    })
        
        if not results:
            return "í•´ë‹¹ ì œí’ˆì˜ í• ì¸ ê¸°ê°„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        return {
            "type": "product_list",
            "text": "í• ì¸ ê¸°ê°„ ì •ë³´:\n\n" + "\n\n".join([r["text"] for r in results]),
            "products": [r["product_name"] for r in results]
        }

    if intent == "DISCOUNT" and not start_date:
        df = df_work[df_work["is_discount"] == True]
        if df.empty:
            return None
        
        # ìƒì„¸ ì •ë³´ í¬í•¨í•œ ê²°ê³¼ ìƒì„±
        results = []
        for _, row in df.iterrows():
            # ì¹´í…Œê³ ë¦¬ ì •ë³´ êµ¬ì„±
            categories = []
            if pd.notna(row.get("category1")) and row["category1"]:
                categories.append(row["category1"])
            if pd.notna(row.get("category2")) and row["category2"]:
                categories.append(row["category2"])
            
            category_str = f" [{' > '.join(categories)}]" if categories else ""
            
            product_name = row['product_name']
            
            results.append({
                "text": f"â€¢ **{row['brand']}** - {product_name}{category_str}\n  ğŸ’° í˜„ì¬ê°€: {float(row['current_unit_price']):,.1f}ì›",
                "product_name": product_name
            })
        
        if not results:
            return None
        
        return {
            "type": "product_list",
            "text": "í˜„ì¬ í• ì¸ ì¤‘ ì œí’ˆ:\n\n" + "\n\n".join([r["text"] for r in results]),
            "products": [r["product_name"] for r in results]
        }

    if intent == "PRICE_MIN":
        df_valid = df_work[df_work["current_unit_price"] > 0]
        if df_valid.empty:
            return "í˜„ì¬ íŒë§¤ ì¤‘ì¸ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."

        min_price = df_valid["current_unit_price"].min()
        df_min = df_valid[df_valid["current_unit_price"] == min_price]

        output_lines = []
        for _, row in df_min.iterrows():
            res = (
                supabase.table("product_all_events")
                .select("date, unit_price")
                .eq("product_url", row["product_url"])
                .execute()
            )
            if not res.data:
                continue

            df_hist = pd.DataFrame(res.data)
            df_hist["date"] = pd.to_datetime(df_hist["date"])
            df_hist["unit_price"] = df_hist["unit_price"].astype(float)
            df_hist = df_hist[df_hist["unit_price"] > 0]

            df_low = df_hist[df_hist["unit_price"] == min_price]
            if df_low.empty:
                continue

            sd = df_low["date"].min().date()
            ed = df_low["date"].max().date()
            output_lines.append(
                f"- {row['product_name']} / {min_price:,.1f}ì›\n"
                f"  ìµœì €ê°€ ê¸°ê°„: {sd} ~ {ed}"
            )

        if not output_lines:
            return "ìµœì €ê°€ ê³„ì‚° ëŒ€ìƒ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."

        return "ìµœì €ê°€ ì œí’ˆ ëª©ë¡:\n\n" + "\n\n".join(output_lines)

    if intent == "PRICE_MAX":
        df = df_work[df_work["current_unit_price"] > 0].sort_values("current_unit_price", ascending=False)
        if df.empty:
            return None
        top = df.iloc[0]
        return f"ê°€ì¥ ë¹„ì‹¼ ì œí’ˆì€ '{top['product_name']}'ì´ë©° {float(top['current_unit_price']):,.1f}ì›ì…ë‹ˆë‹¤."

    if intent == "NEW":
        res = (
            supabase.table("product_lifecycle_events")
            .select("product_url, date")
            .eq("lifecycle_event", "NEW_PRODUCT")
        )
        
        # ğŸ”¥ ì¡°íšŒ ê¸°ê°„ í•„í„°ë§
        if date_from:
            res = res.gte("date", date_from.strftime("%Y-%m-%d"))
        if date_to:
            res = res.lte("date", date_to.strftime("%Y-%m-%d"))
        
        res = res.execute()
        
        if not res.data:
            return None
        
        # URLê³¼ ì¶œì‹œ ë‚ ì§œ ë§¤í•‘
        new_product_data = {r["product_url"]: r["date"] for r in res.data}
        urls = list(new_product_data.keys())
        
        df = df_work[df_work["product_url"].isin(urls)]
        if df.empty:
            return None
        
        # ìƒì„¸ ì •ë³´ í¬í•¨í•œ ê²°ê³¼ ìƒì„±
        results = []
        for _, row in df.iterrows():
            launch_date = new_product_data.get(row["product_url"])
            
            # ì¹´í…Œê³ ë¦¬ ì •ë³´ êµ¬ì„±
            categories = []
            if pd.notna(row.get("category1")) and row["category1"]:
                categories.append(row["category1"])
            if pd.notna(row.get("category2")) and row["category2"]:
                categories.append(row["category2"])
            
            category_str = f" [{' > '.join(categories)}]" if categories else ""
            
            # ğŸ”¥ ì²´í¬ë°•ìŠ¤ ì¶”ê°€ ê°€ëŠ¥í•˜ë„ë¡ ì œí’ˆëª…ë§Œ í¬í•¨
            product_name = row['product_name']
            
            results.append({
                "text": f"â€¢ **{row['brand']}** - {product_name}{category_str}\n  ğŸ‰ ì¶œì‹œì¼: {launch_date}",
                "product_name": product_name
            })
        
        if not results:
            return None
        
        # ì²´í¬ë°•ìŠ¤ì™€ í…ìŠ¤íŠ¸ ë¶„ë¦¬ ë°˜í™˜
        return {
            "type": "product_list",
            "text": "ìµœê·¼ ì‹ ì œí’ˆ:\n\n" + "\n\n".join([r["text"] for r in results]),
            "products": [r["product_name"] for r in results]
        }

    if intent == "OUT":
        res = (
            supabase.table("product_lifecycle_events")
            .select("product_url, date")
            .eq("lifecycle_event", "OUT_OF_STOCK")
        )
        
        # ğŸ”¥ ì¡°íšŒ ê¸°ê°„ í•„í„°ë§
        if date_from:
            res = res.gte("date", date_from.strftime("%Y-%m-%d"))
        if date_to:
            res = res.lte("date", date_to.strftime("%Y-%m-%d"))
        
        res = res.execute()
        
        if not res.data:
            return None
        
        # URLê³¼ í’ˆì ˆ ë‚ ì§œ ë§¤í•‘
        out_of_stock_data = {r["product_url"]: r["date"] for r in res.data}
        urls = list(out_of_stock_data.keys())
        
        df = df_work[df_work["product_url"].isin(urls)]
        if df.empty:
            return None
        
        # ìƒì„¸ ì •ë³´ í¬í•¨í•œ ê²°ê³¼ ìƒì„±
        results = []
        for _, row in df.iterrows():
            out_date = out_of_stock_data.get(row["product_url"])
            
            # ì¹´í…Œê³ ë¦¬ ì •ë³´ êµ¬ì„±
            categories = []
            if pd.notna(row.get("category1")) and row["category1"]:
                categories.append(row["category1"])
            if pd.notna(row.get("category2")) and row["category2"]:
                categories.append(row["category2"])
            
            category_str = f" [{' > '.join(categories)}]" if categories else ""
            
            product_name = row['product_name']
            
            results.append({
                "text": f"â€¢ **{row['brand']}** - {product_name}{category_str}\n  ğŸ“… í’ˆì ˆì¼: {out_date}",
                "product_name": product_name
            })
        
        if not results:
            return None
        
        return {
            "type": "product_list",
            "text": "ìµœê·¼ í’ˆì ˆ ì œí’ˆ:\n\n" + "\n\n".join([r["text"] for r in results]),
            "products": [r["product_name"] for r in results]
        }

    if intent == "RESTORE":
        res = (
            supabase.table("product_lifecycle_events")
            .select("product_url, date")
            .eq("lifecycle_event", "RESTOCK")
        )
        
        # ğŸ”¥ ì¡°íšŒ ê¸°ê°„ í•„í„°ë§
        if date_from:
            res = res.gte("date", date_from.strftime("%Y-%m-%d"))
        if date_to:
            res = res.lte("date", date_to.strftime("%Y-%m-%d"))
        
        res = res.execute()
        
        if not res.data:
            return None
        
        # URLê³¼ ë³µì› ë‚ ì§œ ë§¤í•‘
        restock_data = {r["product_url"]: r["date"] for r in res.data}
        urls = list(restock_data.keys())
        
        df = df_work[df_work["product_url"].isin(urls)]
        if df.empty:
            return None
        
        # ìƒì„¸ ì •ë³´ í¬í•¨í•œ ê²°ê³¼ ìƒì„±
        results = []
        for _, row in df.iterrows():
            restock_date = restock_data.get(row["product_url"])
            
            # ì¹´í…Œê³ ë¦¬ ì •ë³´ êµ¬ì„±
            categories = []
            if pd.notna(row.get("category1")) and row["category1"]:
                categories.append(row["category1"])
            if pd.notna(row.get("category2")) and row["category2"]:
                categories.append(row["category2"])
            
            category_str = f" [{' > '.join(categories)}]" if categories else ""
            
            product_name = row['product_name']
            
            results.append({
                "text": f"â€¢ **{row['brand']}** - {product_name}{category_str}\n  ğŸ”„ ë³µì›ì¼: {restock_date}",
                "product_name": product_name
            })
        
        if not results:
            return None
        
        return {
            "type": "product_list",
            "text": "ìµœê·¼ ë³µì›ëœ ì œí’ˆ:\n\n" + "\n\n".join([r["text"] for r in results]),
            "products": [r["product_name"] for r in results]
        }

    if intent == "VOLATILITY" and start_date:
        res = (
            supabase.table("product_all_events")
            .select("product_url, unit_price, date")
            .gte("date", start_date.strftime("%Y-%m-%d"))
            .execute()
        )
        if not res.data:
            return None

        df = pd.DataFrame(res.data)
        df["unit_price"] = df["unit_price"].astype(float)

        volatility = (
            df.groupby("product_url")["unit_price"]
            .agg(lambda x: x.max() - x.min())
            .sort_values(ascending=False)
        )

        if volatility.empty:
            return None

        top_url = volatility.index[0]
        top_value = volatility.iloc[0]

        row = df_work[df_work["product_url"] == top_url]
        if row.empty:
            return None

        return (
            f"ìµœê·¼ ê¸°ê°„ ê°€ê²© ë³€ë™ í­ì´ ê°€ì¥ í° ì œí’ˆì€ "
            f"'{row.iloc[0]['product_name']}'ì´ë©° "
            f"ë³€ë™í­ì€ {top_value:,.1f}ì›ì…ë‹ˆë‹¤."
        )

    if intent == "NORMAL_CHANGE":
        start_date = extract_period(question)

        query = supabase.table("product_normal_price_events").select("*")
        if start_date:
            query = query.gte("date", start_date.strftime("%Y-%m-%d"))

        res = query.order("date", desc=True).execute()
        if not res.data:
            return "í•´ë‹¹ ê¸°ê°„ ë‚´ ì •ìƒê°€ ë³€ë™ì´ ì—†ìŠµë‹ˆë‹¤."

        df = pd.DataFrame(res.data)
        results = []

        for _, row in df.iterrows():
            product_row = df_summary[df_summary["product_url"] == row["product_url"]]
            if product_row.empty:
                continue

            pname = product_row.iloc[0]["product_name"]
            results.append(
                f"- {pname} / {float(row['prev_price']):,.0f}ì› â†’ "
                f"{row['date']}ì— {float(row['normal_price']):,.0f}ì› "
                f"({float(row['price_diff']):+,.0f}ì›)"
            )

        return "ê¸°ê°„ ë‚´ ì •ìƒê°€ ë³€ë™ ì œí’ˆ ëª©ë¡:\n" + "\n".join(results) if results else "í•´ë‹¹ ê¸°ê°„ ë‚´ ì •ìƒê°€ ë³€ë™ì´ ì—†ìŠµë‹ˆë‹¤."

    return None

def llm_fallback(question: str, df_summary: pd.DataFrame):
    context = df_summary.head(50)[
        ["product_name", "current_unit_price", "is_discount", "is_new_product", "brew_type_kr"]
    ].to_dict(orient="records")

    prompt = f"""
ë‹¹ì‹ ì€ ì»¤í”¼ ìº¡ìŠ ê°€ê²© ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

ë°ì´í„°:
{context}

ì§ˆë¬¸:
{question}
"""

    from openai import OpenAI
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )

    return response.choices[0].message.content

# =========================
# 3ï¸âƒ£ ìœ í‹¸ (ì œí’ˆëª… ë³´ì • í¬í•¨)
# =========================

import re

def clean_product_name(s: str) -> str:
    """
    ê¹¨ì§„ í•œê¸€(ï¿½) ë° ìì£¼ ë°œìƒí•˜ëŠ” ì¸ì½”ë”© ì˜¤ë¥˜ íŒ¨í„´ ë³´ì •
    """
    if s is None:
        return ""

    s = str(s)

    # ì œì–´ë¬¸ì ì œê±°
    s = re.sub(r"[\x00-\x1f\x7f-\x9f]", "", s).strip()

    # ğŸ”¥ ìì£¼ ê¹¨ì§€ëŠ” íŒ¨í„´ ì‚¬ì „
    fix_map = {
        "ë³¸ï¿½ï¿½ï¿½ì§ì˜": "ë³¸ì‚¬ì§ì˜",
        "ë³¸ï¿½ï¿½ì§ì˜": "ë³¸ì‚¬ì§ì˜",
        "ë³¸ï¿½ì§ì˜": "ë³¸ì‚¬ì§ì˜",

        "ë°”ë‹ï¿½ï¿½ï¿½í–¥": "ë°”ë‹ë¼í–¥",
        "ë°”ë‹ï¿½ï¿½í–¥": "ë°”ë‹ë¼í–¥",

        "ë„¤ìŠ¤í”„ï¿½ï¿½ï¿½": "ë„¤ìŠ¤í”„ë ˆì†Œ",
        "ìŠ¤íƒ€ï¿½ï¿½ï¿½ìŠ¤": "ìŠ¤íƒ€ë²…ìŠ¤",
    }

    for bad, good in fix_map.items():
        if bad in s:
            s = s.replace(bad, good)

    # ğŸ”¥ íŒ¨í„´ ê¸°ë°˜ ë³´ì •
    s = re.sub(r"ë°”ë‹.*?í–¥", "ë°”ë‹ë¼í–¥", s)
    s = re.sub(r"ë³¸.*?ì§ì˜", "ë³¸ì‚¬ì§ì˜", s)

    # ì—°ì†ëœ ê¹¨ì§„ ë¬¸ì ì œê±°
    s = re.sub(r"ï¿½{1,}", "", s)

    # ê³µë°± ì •ë¦¬
    s = re.sub(r"\s{2,}", " ", s).strip()

    return s

def detect_encoding_issues(df: pd.DataFrame):
    if "product_name_raw" not in df.columns:
        return

    mask = df["product_name_raw"].str.contains("ï¿½", na=False)
    issues = df[mask][["product_url", "product_name_raw"]]

    if not issues.empty:
        import logging
        logging.warning(f"[ENCODING ISSUE] {len(issues)}ê±´ ê°ì§€ë¨")

        try:
            supabase.table("product_name_encoding_issues").insert(
                issues.to_dict(orient="records")
            ).execute()
        except Exception as e:
            logging.error(f"ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")




def _norm_series(s: pd.Series) -> pd.Series:
    """
    ê²€ìƒ‰ ì‹œ None/NaN ì•ˆì „ ì²˜ë¦¬ + ë¬¸ìì—´ ë³€í™˜
    """
    return s.fillna("").astype(str)


def options_from(df: pd.DataFrame, col: str):
    """
    í•„í„° selectboxìš© ê³ ìœ  ê°’ ì¶”ì¶œ
    """
    if col not in df.columns:
        return []

    vals = df[col].dropna().astype(str)
    vals = [v.strip() for v in vals.tolist() if v.strip()]
    return sorted(list(dict.fromkeys(vals)))


# =========================
# ğŸ”§ ì œí’ˆ ì„ íƒ í† ê¸€ í•¨ìˆ˜ (ì•ˆì •í™”)
# =========================
def toggle_product(pname):
    """
    ì œí’ˆ ì„ íƒ/í•´ì œ í† ê¸€
    """

    if "selected_products" not in st.session_state:
        st.session_state.selected_products = set()

    # pnameì´ Noneì´ê±°ë‚˜ ë¹ˆê°’ì´ë©´ ë°©ì–´
    if not pname:
        return

    if pname in st.session_state.selected_products:
        st.session_state.selected_products.remove(pname)
    else:
        st.session_state.selected_products.add(pname)


# =========================
# 4ï¸âƒ£ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# =========================
if "selected_products" not in st.session_state:
    st.session_state.selected_products = set()
if "keyword_results" not in st.session_state:
    st.session_state.keyword_results = {}
if "active_mode" not in st.session_state:
    st.session_state.active_mode = "í‚¤ì›Œë“œ ê²€ìƒ‰"
if "show_results" not in st.session_state:
    st.session_state.show_results = False
if "search_keyword" not in st.session_state:
    st.session_state.search_keyword = ""
if "search_history" not in st.session_state:
    st.session_state.search_history = []  # ğŸ”¥ ê²€ìƒ‰ ì´ë ¥ [{keyword: "ì¥¬ì‹œ", results: [...]}]

# =========================
# 5ï¸âƒ£ ë©”ì¸ UI
# =========================
st.title("â˜• Capsule Price Intelligence")

# -------------------------
# ë°ì´í„° ë¡œë”© (íƒ­ ì´ì „ì— ë¡œë“œ)
# -------------------------
df_all = load_product_summary()

# ë°ì´í„° ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¤‘ë‹¨
if df_all is None or df_all.empty:
    st.warning("ì•„ì§ ì§‘ê³„ëœ ì œí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# -------------------------
# ì œí’ˆëª… ì •ì œ
# -------------------------
df_all["product_name_raw"] = df_all["product_name"]
df_all["product_name"] = df_all["product_name"].apply(clean_product_name)

# -------------------------
# ê¹¨ì§„ ë¬¸ìì—´ ê°ì§€ (ìš´ì˜ ë¡œê·¸ ì „ìš©)
# -------------------------
try:
    encoding_issues = detect_encoding_issues(df_all)

    if isinstance(encoding_issues, pd.DataFrame) and not encoding_issues.empty:
        print(f"[ENCODING] ê¹¨ì§„ ì œí’ˆëª… {len(encoding_issues)}ê±´ ê°ì§€")

        # Supabase ì €ì¥ìš© ìµœì†Œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        log_records = encoding_issues[[
            "product_url",
            "product_name_raw"
        ]].to_dict(orient="records")

        supabase.table("product_name_encoding_issues") \
                .insert(log_records) \
                .execute()

except Exception as e:
    print(f"[ENCODING_LOG_ERROR] {e}")

# -------------------------
# ì¡°íšŒ ê¸°ì¤€ ì„ íƒ ë° ì¡°íšŒ ì¡°ê±´ í†µí•©
# -------------------------
col_main_left, col_main_right = st.columns([3, 1])

with col_main_left:
    st.subheader("ğŸ” ì¡°íšŒ ê¸°ì¤€")

with col_main_right:
    st.subheader("ğŸ“… ì¡°íšŒ ê¸°ê°„")

# ğŸ”¥ ë©”ì¸ ë ˆì´ì•„ì›ƒ: íƒ­(ì¢Œ) + ì¡°íšŒì¡°ê±´(ìš°)
col_tabs, col_controls = st.columns([3, 1])

with col_controls:
    # ğŸ”¥ ì‹œì‘ì¼/ì¢…ë£Œì¼ì„ í•œ ì¤„ì— ë°°ì¹˜
    col_from, col_to = st.columns(2)
    with col_from:
        st.write("ì‹œì‘ì¼")
        date_from = st.date_input(
            "ì‹œì‘ì¼",
            value=datetime.now() - timedelta(days=90),
            key="date_from",
            label_visibility="collapsed"
        )
    with col_to:
        st.write("ì¢…ë£Œì¼")
        date_to = st.date_input(
            "ì¢…ë£Œì¼",
            value=datetime.now(),
            key="date_to",
            label_visibility="collapsed"
        )
    
    st.button("ğŸ“Š ì¡°íšŒí•˜ê¸°", type="primary", use_container_width=True, key="btn_search_trigger", on_click=lambda: st.session_state.update({"show_results": True}))
    
    if st.button("ğŸ—‘ï¸ ì „ì²´ ì´ˆê¸°í™”", use_container_width=True, key="btn_reset_all"):
        # ğŸ”¥ ëª¨ë“  ì„¸ì…˜ ìƒíƒœ ì™„ì „ ì´ˆê¸°í™”
        st.session_state.selected_products = set()
        st.session_state.keyword_results = {}
        st.session_state.show_results = False
        st.session_state.search_keyword = ""
        st.session_state.search_history = []
        
        # ğŸ”¥ ì§ˆë¬¸ ì…ë ¥ì°½ ë° ì´ë ¥ ì´ˆê¸°í™”
        if "insight_question" in st.session_state:
            del st.session_state.insight_question
        if "insight_question_input" in st.session_state:
            del st.session_state.insight_question_input
        if "question_history" in st.session_state:
            del st.session_state.question_history
        
        # ğŸ”¥ ê¸°ê°„ ì´ˆê¸°í™”
        if "date_from" in st.session_state:
            del st.session_state.date_from
        if "date_to" in st.session_state:
            del st.session_state.date_to
        
        # ğŸ”¥ í•„í„° selectbox ìƒíƒœ ì´ˆê¸°í™”
        if "filter_brand" in st.session_state:
            del st.session_state.filter_brand
        if "filter_cat1" in st.session_state:
            del st.session_state.filter_cat1
        if "filter_cat2" in st.session_state:
            del st.session_state.filter_cat2
        
        # ğŸ”¥ ëª¨ë“  ì²´í¬ë°•ìŠ¤ ë° ë²„íŠ¼ í‚¤ ì‚­ì œ (ê²€ìƒ‰ ê²°ê³¼ ì¹´ë“œ ì œê±°ìš©)
        keys_to_delete = [key for key in st.session_state.keys() if key.startswith(("chk_kw_", "chk_filter_", "chk_nlp_", "delete_search_", "delete_q_"))]
        for key in keys_to_delete:
            del st.session_state[key]
        
        st.rerun()

with col_tabs:
    tab1, tab2, tab3 = st.tabs(["ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰", "ğŸ›ï¸ í•„í„° ì„ íƒ", "ğŸ¤– ìì—°ì–´ ì§ˆë¬¸"])

    # =========================
    # TAB 1: í‚¤ì›Œë“œ ê²€ìƒ‰
    # =========================
    with tab1:
        # ğŸ” ê²€ìƒ‰ ì…ë ¥ (Enter ê°€ëŠ¥)
        with st.form("search_form", clear_on_submit=True):
            keyword_input = st.text_input(
                "ì œí’ˆëª… ê²€ìƒ‰",
                placeholder="ì˜ˆ: ì¥¬ì‹œ, ë©œë¡œì§€ì˜¤",
                key="keyword_input_field"
            )
            submitted = st.form_submit_button("ê²€ìƒ‰")

        if submitted and keyword_input.strip():
            search_keyword = keyword_input.strip()
            st.session_state.search_keyword = search_keyword
            st.session_state.active_mode = "í‚¤ì›Œë“œ ê²€ìƒ‰"
            
            # ğŸ”¥ ê²€ìƒ‰ ê²°ê³¼ ê³„ì‚°
            keywords = [k.strip() for k in search_keyword.split(",") if k.strip()]
            mask = False
            for kw in keywords:
                mask |= _norm_series(df_all["product_name"]).str.contains(kw, case=False)
            candidates_df = df_all[mask].copy()
            
            # ğŸ”¥ í‚¤ì›Œë“œ ê²€ìƒ‰ ë¡œê·¸ ì €ì¥
            try:
                supabase.table("search_logs").insert({
                    "search_type": "KEYWORD",
                    "search_term": search_keyword,
                    "result_count": len(candidates_df),
                    "created_at": datetime.now().isoformat()
                }).execute()
            except Exception as e:
                print("ê²€ìƒ‰ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨:", e)
            
            # ğŸ”¥ ê²€ìƒ‰ ì´ë ¥ì— ì¶”ê°€ (ì¤‘ë³µ ê²€ìƒ‰ì–´ëŠ” ë®ì–´ì“°ê¸°)
            existing_idx = None
            for idx, history in enumerate(st.session_state.search_history):
                if history["keyword"] == search_keyword:
                    existing_idx = idx
                    break
            
            search_result = {
                "keyword": search_keyword,
                "results": sorted(candidates_df["product_name"].unique().tolist()) if not candidates_df.empty else []
            }
            
            if existing_idx is not None:
                st.session_state.search_history[existing_idx] = search_result
            else:
                st.session_state.search_history.append(search_result)
            
            st.rerun()

        # ğŸ“¦ ì œí’ˆ ì„ íƒ - ê²€ìƒ‰ ì´ë ¥ë³„ë¡œ êµ¬íší™”
        st.markdown("### ğŸ“¦ ë¹„êµí•  ì œí’ˆ ì„ íƒ")
        
        if not st.session_state.search_history:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ğŸ”¥ ê²€ìƒ‰ì–´ë¥¼ 3ê°œì”© ê°€ë¡œë¡œ ë°°ì—´
            num_cols = 3
            total_searches = len(st.session_state.search_history)
            
            for row_idx in range(0, total_searches, num_cols):
                cols = st.columns(num_cols)
                
                for col_idx in range(num_cols):
                    history_idx = row_idx + col_idx
                    
                    if history_idx >= total_searches:
                        break
                    
                    history = st.session_state.search_history[history_idx]
                    
                    with cols[col_idx]:
                        # ğŸ”¥ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ
                        with st.container(border=True):
                            # ê²€ìƒ‰ì–´ ì œëª©ê³¼ ì‚­ì œ ë²„íŠ¼
                            col_title, col_delete = st.columns([4, 1])
                            
                            with col_title:
                                st.markdown(f"**ğŸ” {history['keyword']}**")
                            
                            with col_delete:
                                if st.button("ğŸ—‘ï¸", key=f"delete_search_{history_idx}", help="ê²€ìƒ‰ ê²°ê³¼ ì‚­ì œ"):
                                    # í•´ë‹¹ ê²€ìƒ‰ ê²°ê³¼ì˜ ì œí’ˆë“¤ì„ ì„ íƒì—ì„œ ì œê±°
                                    for pname in history['results']:
                                        if pname in st.session_state.selected_products:
                                            st.session_state.selected_products.remove(pname)
                                    
                                    # ê²€ìƒ‰ ì´ë ¥ì—ì„œ ì œê±°
                                    st.session_state.search_history.pop(history_idx)
                                    st.rerun()
                            
                            st.markdown("---")
                            
                            if not history['results']:
                                st.caption("ğŸ“­ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                            else:
                                # ì œí’ˆ ì²´í¬ë°•ìŠ¤
                                for pname in history['results']:
                                    st.checkbox(
                                        pname,
                                        value=pname in st.session_state.selected_products,
                                        key=f"chk_kw_{history_idx}_{pname}",
                                        on_change=toggle_product,
                                        args=(pname,)
                                    )

    # =========================
    # TAB 2: í•„í„° ì„ íƒ
    # =========================
    with tab2:
        col1, col2, col3 = st.columns(3)

        with col1:
            brands = options_from(df_all, "brand")
            sel_brand = st.selectbox(
                "ë¸Œëœë“œ",
                ["(ì „ì²´)"] + brands,
                key="filter_brand"
            )

        df1 = df_all if sel_brand == "(ì „ì²´)" else df_all[df_all["brand"] == sel_brand]

        with col2:
            cat1s = options_from(df1, "category1")
            sel_cat1 = st.selectbox(
                "ì¹´í…Œê³ ë¦¬1",
                ["(ì „ì²´)"] + cat1s,
                key="filter_cat1"
            )

        df2 = df1 if sel_cat1 == "(ì „ì²´)" else df1[df1["category1"] == sel_cat1]

        with col3:
            cat2s = options_from(df2, "category2")
            sel_cat2 = st.selectbox(
                "ì¹´í…Œê³ ë¦¬2",
                ["(ì „ì²´)"] + cat2s,
                key="filter_cat2"
            )

        candidates_df = df2 if sel_cat2 == "(ì „ì²´)" else df2[df2["category2"] == sel_cat2]
        
        # í•„í„° ë³€ê²½ ì‹œ active_mode ì—…ë°ì´íŠ¸ ë° ë¡œê·¸ ì €ì¥
        if sel_brand != "(ì „ì²´)" or sel_cat1 != "(ì „ì²´)" or sel_cat2 != "(ì „ì²´)":
            st.session_state.active_mode = "í•„í„° ì„ íƒ"
            
            # ğŸ”¥ í•„í„° ì„ íƒ ë¡œê·¸ ì €ì¥ (ì´ì „ ìƒíƒœì™€ ë¹„êµí•˜ì—¬ ë³€ê²½ ì‹œë§Œ ì €ì¥)
            current_filter = f"{sel_brand}|{sel_cat1}|{sel_cat2}"
            if "last_filter" not in st.session_state or st.session_state.last_filter != current_filter:
                try:
                    supabase.table("search_logs").insert({
                        "search_type": "FILTER",
                        "search_term": current_filter,
                        "filter_data": {
                            "brand": sel_brand,
                            "category1": sel_cat1,
                            "category2": sel_cat2
                        },
                        "result_count": len(candidates_df),
                        "created_at": datetime.now().isoformat()
                    }).execute()
                    st.session_state.last_filter = current_filter
                except Exception as e:
                    print("í•„í„° ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨:", e)

        st.markdown("### ğŸ“¦ ë¹„êµí•  ì œí’ˆ ì„ íƒ")

        with st.expander("ëª©ë¡ í¼ì¹˜ê¸° / ì ‘ê¸°", expanded=False):
            for pname in sorted(candidates_df["product_name"].unique()):
                st.checkbox(
                    pname,
                    value=pname in st.session_state.selected_products,
                    key=f"chk_filter_{pname}",
                    on_change=toggle_product,
                    args=(pname,)
                )

    # =========================
    # TAB 3: ìì—°ì–´ ì§ˆë¬¸
    # =========================
    with tab3:
        # ğŸ”¥ Formì„ ì‚¬ìš©í•˜ì—¬ ì œì¶œ í›„ ìë™ìœ¼ë¡œ ì…ë ¥ì°½ ë¹„ìš°ê¸°
        with st.form("question_form", clear_on_submit=True):
            question = st.text_area(
                "ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”",
                placeholder="ì˜ˆ:\n- ë„¤ìŠ¤í”„ë ˆì†Œ ì¤‘ ìµœì €ê°€ëŠ”?\n- ìµœê·¼ 1ê°œì›” í• ì¸ ì œí’ˆ\n- ì—ìŠ¤í”„ë ˆì†Œ í’ˆì ˆ ì œí’ˆ",
                height=100,
                key="insight_question_input"
            )
            ask_question = st.form_submit_button("ğŸ” ì§ˆë¬¸í•˜ê¸°", type="primary", use_container_width=True)
    
        # ğŸ”¥ ì§ˆë¬¸ ì²˜ë¦¬
        if ask_question and question:
            st.session_state.active_mode = "ìì—°ì–´ ì§ˆë¬¸"
        
            # ğŸ”¥ ìƒˆ ì§ˆë¬¸ ì‹œ ì´ì „ ì§ˆë¬¸ ì´ë ¥ ëª¨ë‘ ì‚­ì œ
            st.session_state.question_history = []
        
            intent = classify_intent(question)
        
            # ğŸ”¥ ê¸°ê°„ ì„¤ì • (ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
            date_from = st.session_state.get("date_from", datetime.now() - timedelta(days=90))
            date_to = st.session_state.get("date_to", datetime.now())
        
            # ë‚ ì§œ ê°ì²´ë¡œ ë³€í™˜ (í•„ìš”ì‹œ)
            if not isinstance(date_from, datetime):
                date_from = datetime.combine(date_from, datetime.min.time()) if hasattr(date_from, 'year') else datetime.now() - timedelta(days=90)
            if not isinstance(date_to, datetime):
                date_to = datetime.combine(date_to, datetime.min.time()) if hasattr(date_to, 'year') else datetime.now()
        
            # ğŸ”¥ í˜„ì¬ ê²€ìƒ‰/í•„í„° ì¡°ê±´ì„ ë°˜ì˜í•œ ë°ì´í„°ì…‹ ìƒì„±
            filtered_df = df_all.copy()
        
            # ğŸ”¥ ì¡°íšŒ ê¸°ê°„ ì ìš© (ë¸Œëœë“œ/ì œí’ˆëª… í•„í„°ë§ì€ execute_ruleì—ì„œ ì²˜ë¦¬)
            answer = execute_rule(intent, question, filtered_df, date_from, date_to)

            # ğŸ”¥ í•„í„° ì •ë³´ ìˆ˜ì§‘
            filter_info = {
                "date_from": date_from.strftime("%Y-%m-%d") if hasattr(date_from, 'strftime') else str(date_from),
                "date_to": date_to.strftime("%Y-%m-%d") if hasattr(date_to, 'strftime') else str(date_to),
                "total_products": len(filtered_df),
                "filtered": len(filtered_df) < len(df_all)
            }

            if answer:
                # ğŸ”¥ ë¡œê·¸ ì €ì¥ (ë‹µë³€ í¬í•¨)
                save_question_log(question, intent, False, answer, filter_info)
            
                # ğŸ”¥ ë‹µë³€ì„ ì§ˆë¬¸ ì´ë ¥ì— ì €ì¥
                st.session_state.question_history.append({
                    "question": question,
                    "answer": answer,
                    "intent": intent
                })
            
            else:
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    answer = llm_fallback(question, filtered_df)
                    answer = {"type": "text", "text": answer}  # í†µì¼ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                
                # ğŸ”¥ ë¡œê·¸ ì €ì¥ (ë‹µë³€ í¬í•¨)
                save_question_log(question, intent, True, answer, filter_info)
            
                # ğŸ”¥ ë‹µë³€ì„ ì§ˆë¬¸ ì´ë ¥ì— ì €ì¥
                st.session_state.question_history.append({
                    "question": question,
                    "answer": answer,
                    "intent": intent
                })
        
            # ğŸ”¥ ì§ˆë¬¸ ì²˜ë¦¬ í›„ Formì´ ìë™ìœ¼ë¡œ ì…ë ¥ì°½ ë¹„ì›€
            st.rerun()
    
        # ğŸ”¥ ì§ˆë¬¸ ì´ë ¥ í‘œì‹œ
        if "question_history" in st.session_state and st.session_state.question_history:
            st.markdown("---")
        
            for idx, history in enumerate(reversed(st.session_state.question_history)):
                with st.container(border=True):
                    col_q, col_del = st.columns([10, 1])
                
                    with col_q:
                        st.markdown(f"**Q:** {history['question']}")
                
                    with col_del:
                        if st.button("ğŸ—‘ï¸", key=f"delete_q_{idx}", help="ì§ˆë¬¸ ì‚­ì œ"):
                            st.session_state.question_history.pop(len(st.session_state.question_history) - 1 - idx)
                            st.rerun()
                
                    # ğŸ”¥ ë‹µë³€ í‘œì‹œ
                    answer_data = history['answer']
                
                    if isinstance(answer_data, dict) and answer_data.get("type") == "product_list":
                        # ì œí’ˆ ëª©ë¡ì´ ìˆëŠ” ê²½ìš°
                        st.markdown(f"**A:** {answer_data['text']}")
                    
                        # ì²´í¬ë°•ìŠ¤ ì¶”ê°€
                        if answer_data.get("products"):
                            st.markdown("##### ğŸ“¦ ë¹„êµí•  ì œí’ˆìœ¼ë¡œ ì¶”ê°€")
                            cols = st.columns(3)
                            for pidx, pname in enumerate(answer_data["products"]):
                                with cols[pidx % 3]:
                                    st.checkbox(
                                        pname,
                                        value=pname in st.session_state.selected_products,
                                        key=f"chk_nlp_{idx}_{pidx}_{pname}",
                                        on_change=toggle_product,
                                        args=(pname,)
                                    )
                    elif isinstance(answer_data, dict):
                        # ë”•ì…”ë„ˆë¦¬ì§€ë§Œ product_listê°€ ì•„ë‹Œ ê²½ìš°
                        st.markdown(f"**A:** {answer_data.get('text', str(answer_data))}")
                    else:
                        # ì¼ë°˜ í…ìŠ¤íŠ¸ ë‹µë³€
                        st.markdown(f"**A:** {answer_data}")

st.divider()

# =========================
# 8ï¸âƒ£ ê²°ê³¼ í‘œì‹œ
# =========================
selected_products = list(st.session_state.selected_products)

# ğŸ”¥ ìì—°ì–´ ì§ˆë¬¸ ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ ì œí’ˆ ì„ íƒ í™•ì¸
if st.session_state.get("active_mode") != "ìì—°ì–´ ì§ˆë¬¸":
    if not selected_products:
        st.info("ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.")
        st.stop()

    if not st.session_state.show_results:
        st.info("ì œí’ˆì„ ì„ íƒí•œ ë’¤ 'ì¡°íšŒí•˜ê¸°'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
        st.stop()
else:
    # ìì—°ì–´ ì§ˆë¬¸ ëª¨ë“œì—ì„œëŠ” ì œí’ˆ ì„ íƒ ì—†ì´ë„ ì§„í–‰
    if not selected_products:
        st.stop()  # ì¡°ìš©íˆ ì¤‘ë‹¨

st.divider()
st.subheader(f"ğŸ“Š ì¡°íšŒ ê²°ê³¼ ({len(selected_products)}ê°œ ì œí’ˆ)")

# ğŸ”¥ ê¸°ê°„ ìœ íš¨ì„± ê²€ì‚¬
if date_from > date_to:
    st.error("âŒ ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤. ê¸°ê°„ì„ ë‹¤ì‹œ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

st.info(f"ğŸ“… ì¡°íšŒ ê¸°ê°„: {date_from.strftime('%Y-%m-%d')} ~ {date_to.strftime('%Y-%m-%d')}")

timeline_rows = []
lifecycle_rows = []

# ğŸ”¥ ì„ íƒëœ ê¸°ê°„ ê°€ì ¸ì˜¤ê¸°
filter_date_from = pd.to_datetime(date_from)
filter_date_to = pd.to_datetime(date_to)

for pname in selected_products:
    row = df_all[df_all["product_name"] == pname].iloc[0]

    # ê°€ê²© ì´ë²¤íŠ¸
    df_price = load_events(row["product_url"])
    if not df_price.empty:
        tmp = df_price.copy()
        # ğŸ”¥ ë¸Œëœë“œ + ì œí’ˆëª…ìœ¼ë¡œ í‘œì‹œ
        display_name = f"{row['brand']} - {pname}"
        tmp["product_name"] = display_name
        tmp["event_date"] = pd.to_datetime(tmp["date"])
        
        # ğŸ”¥ ê¸°ê°„ í•„í„° ì ìš©
        tmp = tmp[(tmp["event_date"] >= filter_date_from) & (tmp["event_date"] <= filter_date_to)]
        
        if tmp.empty:
            continue
            
        tmp["unit_price"] = tmp["unit_price"].astype(float)
        
        # ğŸ”¥ í• ì¸ ì—¬ë¶€ ì¶”ê°€
        tmp["is_discount"] = tmp["event_type"] == "DISCOUNT"
        tmp["price_status"] = tmp["is_discount"].map({True: "ğŸ’¸ í• ì¸ ì¤‘", False: "ì •ìƒê°€"})
        
        # ğŸ”¥ lifecycle ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        df_life = load_lifecycle_events(row["product_url"])
        
        if not df_life.empty:
            df_life["date"] = pd.to_datetime(df_life["date"])
        
            # í’ˆì ˆ/ë³µì› êµ¬ê°„ ê³„ì‚°
            out_dates = df_life[df_life["lifecycle_event"] == "OUT_OF_STOCK"]["date"].tolist()
            restore_dates = df_life[df_life["lifecycle_event"] == "RESTOCK"]["date"].tolist()
        
            for out_date in out_dates:
                # í•´ë‹¹ í’ˆì ˆ ì´í›„ ì²« ë³µì› ë‚ ì§œ ì°¾ê¸°
                restore_after = [d for d in restore_dates if d > out_date]
                if restore_after:
                    restore_date = min(restore_after)
        
                    # ğŸ”¥ í’ˆì ˆ(í¬í•¨) ~ ë³µì›(ì œì™¸) ì‚¬ì´ ê°€ê²© ì œê±°
                    mask = (tmp["event_date"] >= out_date) & (tmp["event_date"] < restore_date)
                    tmp.loc[mask, "unit_price"] = None
                else:
                    # ë³µì› ì´ë²¤íŠ¸ê°€ ì—†ìœ¼ë©´ í’ˆì ˆ ì´í›„ ëª¨ë“  ë°ì´í„° ì œê±°
                    mask = tmp["event_date"] >= out_date
                    tmp.loc[mask, "unit_price"] = None
        
        timeline_rows.append(tmp[["product_name", "event_date", "unit_price", "price_status"]])
        

    # lifecycle ì´ë²¤íŠ¸
    df_life = load_lifecycle_events(row["product_url"])
    if not df_life.empty:
        tmp2 = df_life.copy()
        # ğŸ”¥ ë¸Œëœë“œ + ì œí’ˆëª…ìœ¼ë¡œ í‘œì‹œ
        display_name = f"{row['brand']} - {pname}"
        tmp2["product_name"] = display_name
        tmp2["event_date"] = pd.to_datetime(tmp2["date"])
        
        # ğŸ”¥ ê¸°ê°„ í•„í„° ì ìš©
        tmp2 = tmp2[(tmp2["event_date"] >= filter_date_from) & (tmp2["event_date"] <= filter_date_to)]
        
        if not tmp2.empty:
            lifecycle_rows.append(tmp2[["product_name", "event_date", "lifecycle_event"]])

# =========================
# 8-1ï¸âƒ£ ê°œë‹¹ ê°€ê²© íƒ€ì„ë¼ì¸ ë¹„êµ ì°¨íŠ¸
# =========================
if timeline_rows:

    df_timeline = pd.concat(timeline_rows, ignore_index=True)

    # 1ï¸âƒ£ ì •ë ¬ (í•„ìˆ˜)
    df_timeline = df_timeline.sort_values(
        ["product_name", "event_date"]
    )

    # 2ï¸âƒ£ ìˆ«ì ê°•ì œ ë³€í™˜
    df_timeline["unit_price"] = pd.to_numeric(
        df_timeline["unit_price"], errors="coerce"
    )

    # 3ï¸âƒ£ segment ì»¬ëŸ¼ ìƒì„± (ëŠê¹€ ì™„ì „ ë¶„ë¦¬ìš©)
    df_timeline["segment"] = (
        df_timeline["unit_price"].isna()
        .groupby(df_timeline["product_name"])
        .cumsum()
    )

    # 4ï¸âƒ£ NaN ì œê±° (ëŠê¸´ êµ¬ê°„ì€ ì°¨íŠ¸ì—ì„œ ì œì™¸)
    df_chart = df_timeline.dropna(subset=["unit_price"])

    # =========================
    # ğŸ“Š ì°¨íŠ¸ì™€ ë²”ë¡€ë¥¼ ë¶„ë¦¬ëœ ë ˆì´ì•„ì›ƒìœ¼ë¡œ í‘œì‹œ
    # =========================
    col_chart, col_legend = st.columns([3, 1])
    
    with col_chart:
        # =========================
        # ğŸ“ˆ ê°€ê²© ì„  ì°¨íŠ¸ (ë²”ë¡€ ì—†ìŒ)
        # =========================
        base_line = (
            alt.Chart(df_chart)
            .mark_line(point=True)
            .encode(
                x=alt.X("event_date:T", title="ë‚ ì§œ"),
                y=alt.Y("unit_price:Q", title="ê°œë‹¹ ê°€ê²© (ì›)"),
                color=alt.Color("product_name:N", title="ì œí’ˆ", legend=None),  # ğŸ”¥ ë²”ë¡€ ì œê±°
                detail="segment:N",  # ğŸ”¥ ì´ê²Œ í•µì‹¬ (ì„  ì™„ì „ ë¶„ë¦¬)
                tooltip=[
                    alt.Tooltip("product_name:N", title="ì œí’ˆ"),
                    alt.Tooltip("event_date:T", title="ë‚ ì§œ", format="%Y-%m-%d"),
                    alt.Tooltip("unit_price:Q", title="ê°œë‹¹ ê°€ê²©", format=",.1f"),
                    alt.Tooltip("price_status:N", title="ìƒíƒœ"),  # ğŸ”¥ í• ì¸ ì—¬ë¶€ ì¶”ê°€
                ],
            )
        )

        layers = [base_line]

        # =========================
        # ğŸ”” Lifecycle ì•„ì´ì½˜ ì¶”ê°€
        # =========================
        if lifecycle_rows:

            df_life_all = pd.concat(lifecycle_rows, ignore_index=True)

            icon_config = {
                "NEW_PRODUCT": {"color": "green", "label": "NEW"},
                "OUT_OF_STOCK": {"color": "red", "label": "í’ˆì ˆ"},
                "RESTOCK": {"color": "orange", "label": "ë³µì›"},
            }

            for event_type, cfg in icon_config.items():

                df_filtered = df_life_all[
                    df_life_all["lifecycle_event"] == event_type
                ]

                if df_filtered.empty:
                    continue

                # ğŸ”¥ ì•„ì´ì½˜ ìœ„ì¹˜ë¥¼ ê°€ê²©ì„ ì— ë§ì¶”ê¸° ìœ„í•´ join
                df_filtered = df_filtered.merge(
                    df_timeline[["product_name", "event_date", "unit_price"]],
                    on=["product_name", "event_date"],
                    how="left"
                )
                
                # ğŸ”¥ í’ˆì ˆ/ë³µì› ì•„ì´ì½˜ì€ ì‹¤ì œ ê°€ê²©ì„  ìœ„ì—ë§Œ í‘œì‹œ
                if event_type in ["OUT_OF_STOCK", "RESTOCK"]:
                    # í’ˆì ˆ ì‹œì‘ì : í’ˆì ˆ ì§ì „ ê°€ê²© ì‚¬ìš©
                    if event_type == "OUT_OF_STOCK":
                        for idx, row in df_filtered[df_filtered["unit_price"].isna()].iterrows():
                            product_prices = df_timeline[
                                (df_timeline["product_name"] == row["product_name"]) &
                                (df_timeline["event_date"] < row["event_date"]) &
                                (df_timeline["unit_price"].notna())
                            ]
                            if not product_prices.empty:
                                closest = product_prices.nsmallest(1, "event_date").iloc[-1]
                                df_filtered.at[idx, "unit_price"] = closest["unit_price"]
                    
                    # ë³µì› ì‹œì : ë³µì› ë‹¹ì¼ ê°€ê²© ì‚¬ìš© (ì´ë¯¸ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ, ì—†ìœ¼ë©´ ì§í›„ ê°€ê²©)
                    elif event_type == "RESTOCK":
                        # ë³µì› ë‚ ì§œëŠ” ê°€ê²©ì„ ì— í¬í•¨ë˜ë¯€ë¡œ ëŒ€ë¶€ë¶„ unit_priceê°€ ì´ë¯¸ ìˆìŒ
                        # ì—†ëŠ” ê²½ìš°ì—ë§Œ ì§í›„ ê°€ê²© ì‚¬ìš©
                        for idx, row in df_filtered[df_filtered["unit_price"].isna()].iterrows():
                            product_prices = df_timeline[
                                (df_timeline["product_name"] == row["product_name"]) &
                                (df_timeline["event_date"] >= row["event_date"]) &
                                (df_timeline["unit_price"].notna())
                            ]
                            if not product_prices.empty:
                                closest = product_prices.nsmallest(1, "event_date").iloc[0]
                                df_filtered.at[idx, "unit_price"] = closest["unit_price"]
                
                else:
                    # NEW ì´ë²¤íŠ¸: ê°€ì¥ ê°€ê¹Œìš´ ê°€ê²© ì‚¬ìš©
                    for idx, row in df_filtered[df_filtered["unit_price"].isna()].iterrows():
                        product_prices = df_timeline[
                            (df_timeline["product_name"] == row["product_name"]) &
                            (df_timeline["unit_price"].notna())
                        ]
                        
                        if not product_prices.empty:
                            # ì´ë²¤íŠ¸ ë‚ ì§œì™€ ê°€ì¥ ê°€ê¹Œìš´ ê°€ê²© ì°¾ê¸°
                            product_prices["date_diff"] = abs(
                                (product_prices["event_date"] - row["event_date"]).dt.total_seconds()
                            )
                            closest = product_prices.nsmallest(1, "date_diff").iloc[0]
                            df_filtered.at[idx, "unit_price"] = closest["unit_price"]
                
                # unit_price ì—†ëŠ” lifecycle ì œê±° (ë§¤ì¹­ ì‹¤íŒ¨í•œ ê²½ìš°)
                df_filtered = df_filtered.dropna(subset=["unit_price"])

                

                point_layer = (
                   alt.Chart(df_filtered)
                    .mark_point(
                        size=150,
                        shape="triangle-up",
                        color=cfg["color"]
                    )
                    .encode(
                        x="event_date:T",
                        y="unit_price:Q",   # ğŸ”¥ ë°˜ë“œì‹œ ì¶”ê°€
                        tooltip=[
                            alt.Tooltip("product_name:N", title="ì œí’ˆ"),
                            alt.Tooltip("event_date:T", title="ë‚ ì§œ", format="%Y-%m-%d"),
                            alt.Tooltip("unit_price:Q", title="ê°œë‹¹ ê°€ê²©", format=",.1f"),  # ğŸ”¥ ê°€ê²© ì¶”ê°€
                            alt.Tooltip("lifecycle_event:N", title="ì´ë²¤íŠ¸"),
                        ],
                    )
                )

                text_layer = (
                    alt.Chart(df_filtered)
                    .mark_text(
                        dy=12,   # ğŸ”¥ ì•„ë˜ë¡œ 12px ì´ë™
                        fontSize=11,
                        fontWeight="bold",
                        color=cfg["color"]
                    )
                    .encode(
                        x="event_date:T",
                        y="unit_price:Q",   # ğŸ”¥ ë°˜ë“œì‹œ ë™ì¼í•˜ê²Œ
                        text=alt.value(cfg["label"]),
                    )
                )


                layers.append(point_layer)
                layers.append(text_layer)

        chart = (
            alt.layer(*layers)
            .properties(height=420)
            .interactive()
        )

        st.altair_chart(chart, use_container_width=True)
    
    with col_legend:
        st.markdown("#### ğŸ“‹ ì œí’ˆ ëª©ë¡")
        
        # ğŸ”¥ ì œí’ˆë³„ë¡œ ìƒ‰ìƒ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ
        unique_products = sorted(df_chart["product_name"].unique())
        
        for product in unique_products:
            st.markdown(f"**â€¢** {product}")

else:
    st.info("ë¹„êµ ê°€ëŠ¥í•œ ì´ë²¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


st.divider()

# =========================
# 8-2ï¸âƒ£ ì œí’ˆë³„ ì¹´ë“œ
# =========================
for pname in selected_products:
    p = df_all[df_all["product_name"] == pname].iloc[0]
    st.markdown(f"### {p['product_name']}")

    c1, c2, c3, c4 = st.columns(4)

    with c1:
        st.metric("ê°œë‹¹ ê°€ê²©", f"{float(p['current_unit_price']):,.1f}ì›")


    with c2:
    
        # ğŸ”¥ í˜„ì¬ ì„ íƒëœ ê¸°ê°„ ê°€ì ¸ì˜¤ê¸°
        date_from = df_timeline["event_date"].min().date()
        date_to = df_timeline["event_date"].max().date()
    
        res = supabase.rpc(
            "get_discount_periods_in_range",
            {
                "p_product_url": p["product_url"],
                "p_date_from": str(date_from),
                "p_date_to": str(date_to),
            }
        ).execute()
    
        discount_rows = res.data if res.data else []
    
        if discount_rows:
    
            for d in discount_rows:
                st.success(
                    f"ğŸ’¸ í• ì¸ {d['discount_start_date']} ~ {d['discount_end_date']}"
                )
    
        else:
            st.info("ì •ìƒê°€")


    with c3:
        df_life = load_lifecycle_events(p["product_url"])
        has_new = (not df_life.empty) and (df_life["lifecycle_event"] == "NEW_PRODUCT").any()
        if has_new:
            st.warning("ğŸ†• ì‹ ì œí’ˆ")
        else:
            st.caption(f"ê´€ì¸¡ ì‹œì‘ì¼\n{p['first_seen_date']}")

    with c4:
        st.caption(f"ë§ˆì§€ë§‰ ê´€ì¸¡ì¼\n{p['last_seen_date']}")

    if p["product_event_status"] == "NO_EVENT_STABLE":
        st.info("ğŸ“Š ê°€ê²© ë³€ë™ ì—†ìŒ")
    else:
        st.success(f"ğŸ“ˆ ê°€ê²© ì´ë²¤íŠ¸ {p['event_count']}ê±´")

    with st.expander("ğŸ“… ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬"):
        df_price = load_events(p["product_url"])
        df_life = load_lifecycle_events(p["product_url"])

        frames = []

        # 1) ê°€ê²© ì´ë²¤íŠ¸ ì •ì œ
        if not df_price.empty:
            df_price = df_price.copy()
            df_price["date"] = pd.to_datetime(df_price["date"])
            df_price = df_price[df_price["event_type"] != "NORMAL"]
            if not df_price.empty:
                frames.append(df_price[["date", "unit_price", "event_type"]])

        # 2) Lifecycle ì´ë²¤íŠ¸
        if not df_life.empty:
            df_life = df_life[df_life["lifecycle_event"].notna()]
            df_life = df_life.rename(columns={"lifecycle_event": "event_type"})
            df_life["unit_price"] = None
            df_life["date"] = pd.to_datetime(df_life["date"])
            frames.append(df_life[["date", "unit_price", "event_type"]])

        if not frames:
            st.caption("ì´ë²¤íŠ¸ ì—†ìŒ")
            continue

        df_all_events = pd.concat(frames, ignore_index=True)
        df_all_events = df_all_events.drop_duplicates(subset=["date", "event_type"])

        # 4) í• ì¸ êµ¬ê°„ ë¬¶ê¸°
        if not df_price.empty:
            df_discount = df_price[df_price["event_type"] == "DISCOUNT"]
            if not df_discount.empty:
                df_discount = df_discount.sort_values("date")
                df_discount["gap"] = df_discount["date"].diff().dt.days.fillna(1)
                df_discount["group"] = (df_discount["gap"] > 1).cumsum()

                discount_periods = (
                    df_discount.groupby("group")
                    .agg(
                        start_date=("date", "min"),
                        end_date=("date", "max"),
                        unit_price=("unit_price", "first")
                    )
                    .reset_index(drop=True)
                )
            else:
                discount_periods = pd.DataFrame()
        else:
            discount_periods = pd.DataFrame()

        display_rows = []

        for _, row_d in discount_periods.iterrows():
            display_rows.append({
                "ë‚ ì§œ": f"{row_d['start_date'].date()} ~ {row_d['end_date'].date()}",
                "ë‚ ì§œ_ì •ë ¬ìš©": row_d['start_date'],  # ğŸ”¥ ì •ë ¬ìš© ì»¬ëŸ¼ ì¶”ê°€
                "ê°œë‹¹ ê°€ê²©": round(float(row_d["unit_price"]), 1) if pd.notna(row_d["unit_price"]) else None,
                "ì´ë²¤íŠ¸": "ğŸ’¸ í• ì¸ ê¸°ê°„"
            })

        icon_map = {
            "NEW_PRODUCT": "ğŸ†• ì‹ ì œí’ˆ",
            "OUT_OF_STOCK": "âŒ í’ˆì ˆ",
            "RESTOCK": "ğŸ”„ ë³µì›",
        }

        df_lifecycle_only = df_all_events[df_all_events["event_type"].isin(icon_map.keys())]
        for _, row_l in df_lifecycle_only.iterrows():
            display_rows.append({
                "ë‚ ì§œ": str(row_l["date"].date()),
                "ë‚ ì§œ_ì •ë ¬ìš©": row_l["date"],  # ğŸ”¥ ì •ë ¬ìš© ì»¬ëŸ¼ ì¶”ê°€
                "ê°œë‹¹ ê°€ê²©": None,
                "ì´ë²¤íŠ¸": icon_map.get(row_l["event_type"], row_l["event_type"])
            })

        if not display_rows:
            st.caption("ì‹¤ì œ ë³€í™” ì´ë²¤íŠ¸ ì—†ìŒ")
            continue

        df_display = pd.DataFrame(display_rows)
        
        # ğŸ”¥ ì •ë ¬ìš© ì»¬ëŸ¼ìœ¼ë¡œ ì •ë ¬ í›„ ì œê±°
        df_display = df_display.sort_values("ë‚ ì§œ_ì •ë ¬ìš©", ascending=False)
        df_display = df_display.drop(columns=["ë‚ ì§œ_ì •ë ¬ìš©"])

        # ğŸ”¥ None ê°’ ì²˜ë¦¬ - í¬ë§·íŒ… ì „ì— "-"ë¡œ ë³€ê²½
        df_display["ê°œë‹¹ ê°€ê²©"] = df_display["ê°œë‹¹ ê°€ê²©"].apply(
            lambda x: f"{x:.1f}" if pd.notna(x) else "-"
        )

        st.dataframe(
            df_display,
            use_container_width=True,
            hide_index=True
        )
