import streamlit as st
import pandas as pd
import altair as alt
from supabase import create_client
from datetime import datetime, timedelta

# =========================
# 0ï¸âƒ£ ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="Capsule Price Intelligence", layout="wide")

# =========================
# 1ï¸âƒ£ Supabase ì„¤ì •
# =========================
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_ANON_KEY"]
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# =========================
# 2ï¸âƒ£ ë°ì´í„° ë¡œë”©
# =========================
@st.cache_data(ttl=300)
def load_product_summary():
    cols = [
        "product_url",
        "brand",
        "category1",
        "category2",
        "product_name",
        "current_unit_price",
        "is_discount",
        "first_seen_date",
        "last_seen_date",
        "event_count",
        "product_event_status",
        "is_new_product",
        "brew_type_kr",
    ]
    res = supabase.table("product_price_summary_enriched").select(", ".join(cols)).execute()
    return pd.DataFrame(res.data)

@st.cache_data(ttl=300)
def load_events(product_url: str):
    res = (
        supabase.table("product_all_events")
        .select("date, unit_price, event_type")
        .eq("product_url", product_url)
        .order("date", desc=True)
        .execute()
    )
    return pd.DataFrame(res.data)

@st.cache_data(ttl=300)
def load_lifecycle_events(product_url: str):
    res = (
        supabase.table("product_lifecycle_events")
        .select("date, lifecycle_event")
        .eq("product_url", product_url)
        .order("date", desc=True)
        .execute()
    )
    return pd.DataFrame(res.data)

# =========================
# 2-1ï¸âƒ£ ì§ˆë¬¸ ë¡œê·¸ ì €ì¥
# =========================
def save_question_log(question: str, q_type: str, used_llm: bool):
    try:
        supabase.table("question_logs").insert({
            "question_text": question,
            "question_type": q_type,
            "used_llm": used_llm
        }).execute()
    except Exception as e:
        print("ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨:", e)

# =========================
# 3ï¸âƒ£ ìœ í‹¸ (ì œí’ˆëª… ë³´ì • í¬í•¨)
# =========================

import re

def clean_product_name(s: str) -> str:
    """
    ê¹¨ì§„ í•œê¸€(ï¿½) ë° ìì£¼ ë°œìƒí•˜ëŠ” ì¸ì½”ë”© ì˜¤ë¥˜ íŒ¨í„´ ë³´ì •
    """
    if s is None:
        return ""

    s = str(s)

    # ì œì–´ë¬¸ì ì œê±°
    s = re.sub(r"[\x00-\x1f\x7f-\x9f]", "", s).strip()

    # ğŸ”¥ ìì£¼ ê¹¨ì§€ëŠ” íŒ¨í„´ ì‚¬ì „
    fix_map = {
        "ë³¸ï¿½ï¿½ï¿½ì§ì˜": "ë³¸ì‚¬ì§ì˜",
        "ë³¸ï¿½ï¿½ì§ì˜": "ë³¸ì‚¬ì§ì˜",
        "ë³¸ï¿½ì§ì˜": "ë³¸ì‚¬ì§ì˜",

        "ë°”ë‹ï¿½ï¿½ï¿½í–¥": "ë°”ë‹ë¼í–¥",
        "ë°”ë‹ï¿½ï¿½í–¥": "ë°”ë‹ë¼í–¥",

        "ë„¤ìŠ¤í”„ï¿½ï¿½ï¿½": "ë„¤ìŠ¤í”„ë ˆì†Œ",
        "ìŠ¤íƒ€ï¿½ï¿½ï¿½ìŠ¤": "ìŠ¤íƒ€ë²…ìŠ¤",
    }

    for bad, good in fix_map.items():
        if bad in s:
            s = s.replace(bad, good)

    # ğŸ”¥ íŒ¨í„´ ê¸°ë°˜ ë³´ì •
    s = re.sub(r"ë°”ë‹.*?í–¥", "ë°”ë‹ë¼í–¥", s)
    s = re.sub(r"ë³¸.*?ì§ì˜", "ë³¸ì‚¬ì§ì˜", s)

    # ì—°ì†ëœ ê¹¨ì§„ ë¬¸ì ì œê±°
    s = re.sub(r"ï¿½{1,}", "", s)

    # ê³µë°± ì •ë¦¬
    s = re.sub(r"\s{2,}", " ", s).strip()

    return s

def detect_encoding_issues(df: pd.DataFrame):
    if "product_name_raw" not in df.columns:
        return

    mask = df["product_name_raw"].str.contains("ï¿½", na=False)
    issues = df[mask][["product_url", "product_name_raw"]]

    if not issues.empty:
        import logging
        logging.warning(f"[ENCODING ISSUE] {len(issues)}ê±´ ê°ì§€ë¨")

        try:
            supabase.table("product_name_encoding_issues").insert(
                issues.to_dict(orient="records")
            ).execute()
        except Exception as e:
            logging.error(f"ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")




def _norm_series(s: pd.Series) -> pd.Series:
    """
    ê²€ìƒ‰ ì‹œ None/NaN ì•ˆì „ ì²˜ë¦¬ + ë¬¸ìì—´ ë³€í™˜
    """
    return s.fillna("").astype(str)


def options_from(df: pd.DataFrame, col: str):
    """
    í•„í„° selectboxìš© ê³ ìœ  ê°’ ì¶”ì¶œ
    """
    if col not in df.columns:
        return []

    vals = df[col].dropna().astype(str)
    vals = [v.strip() for v in vals.tolist() if v.strip()]
    return sorted(list(dict.fromkeys(vals)))


# =========================
# ğŸ”§ ì œí’ˆ ì„ íƒ í† ê¸€ í•¨ìˆ˜ (ì•ˆì •í™”)
# =========================
def toggle_product(pname):
    """
    ì œí’ˆ ì„ íƒ/í•´ì œ í† ê¸€
    """

    if "selected_products" not in st.session_state:
        st.session_state.selected_products = set()

    # pnameì´ Noneì´ê±°ë‚˜ ë¹ˆê°’ì´ë©´ ë°©ì–´
    if not pname:
        return

    if pname in st.session_state.selected_products:
        st.session_state.selected_products.remove(pname)
    else:
        st.session_state.selected_products.add(pname)


# =========================
# 4ï¸âƒ£ ì„¸ì…˜ ìƒíƒœ
# =========================
if "selected_products" not in st.session_state:
    st.session_state.selected_products = set()
if "keyword_results" not in st.session_state:
    st.session_state.keyword_results = {}
if "active_mode" not in st.session_state:
    st.session_state.active_mode = "í‚¤ì›Œë“œ ê²€ìƒ‰"
if "show_results" not in st.session_state:
    st.session_state.show_results = False
if "keyword_input" not in st.session_state:
    st.session_state.keyword_input = ""  # ğŸ”¥ Enterìš© ìƒíƒœê°’

# =========================
# 5ï¸âƒ£ ë©”ì¸ UI
# =========================
st.title("â˜• Capsule Price Intelligence")

# -------------------------
# ì¡°íšŒ ê¸°ì¤€ ì„ íƒ
# -------------------------
st.subheader("ğŸ” ì¡°íšŒ ê¸°ì¤€")
search_mode = st.radio(
    "ê²€ìƒ‰ ë°©ì‹ ì„ íƒ",
    ["í‚¤ì›Œë“œ ê²€ìƒ‰", "í•„í„° ì„ íƒ (ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬)"],
    horizontal=True
)

if search_mode != st.session_state.active_mode:
    st.session_state.active_mode = search_mode
    st.session_state.selected_products = set()
    st.session_state.keyword_results = {}
    st.session_state.show_results = False
    st.session_state.keyword_input = ""
    st.rerun()

st.divider()


# -------------------------
# ë°ì´í„° ë¡œë”©
# -------------------------
df_all = load_product_summary()

# ë°ì´í„° ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¤‘ë‹¨
if df_all is None or df_all.empty:
    st.warning("ì•„ì§ ì§‘ê³„ëœ ì œí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# -------------------------
# ì œí’ˆëª… ì •ì œ
# -------------------------
df_all["product_name_raw"] = df_all["product_name"]
df_all["product_name"] = df_all["product_name"].apply(clean_product_name)

# -------------------------
# ê¹¨ì§„ ë¬¸ìì—´ ê°ì§€ (ìš´ì˜ ë¡œê·¸ ì „ìš©)
# -------------------------
try:
    encoding_issues = detect_encoding_issues(df_all)

    if isinstance(encoding_issues, pd.DataFrame) and not encoding_issues.empty:
        print(f"[ENCODING] ê¹¨ì§„ ì œí’ˆëª… {len(encoding_issues)}ê±´ ê°ì§€")

        # Supabase ì €ì¥ìš© ìµœì†Œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        log_records = encoding_issues[[
            "product_url",
            "product_name_raw"
        ]].to_dict(orient="records")

        supabase.table("product_name_encoding_issues") \
                .insert(log_records) \
                .execute()

except Exception as e:
    print(f"[ENCODING_LOG_ERROR] {e}")


# -------------------------
# ìƒë‹¨ ë²„íŠ¼
# -------------------------
col_query, col_clear = st.columns([1, 1])

with col_query:
    if st.button("ğŸ“Š ì¡°íšŒí•˜ê¸°", type="primary", use_container_width=True):
        st.session_state.show_results = True

with col_clear:
    if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", use_container_width=True):
        st.session_state.selected_products = set()
        st.session_state.keyword_results = {}
        st.session_state.show_results = False
        st.session_state.keyword_input = ""
        st.rerun()

st.divider()


# =========================
# 6ï¸âƒ£ ì¡°íšŒ ì¡°ê±´
# =========================
st.subheader("ğŸ” ì¡°íšŒ ì¡°ê±´")

with st.form("search_form"):
    keyword_input = st.text_input(
        "ì œí’ˆëª… í‚¤ì›Œë“œ ì…ë ¥",
        placeholder="ì˜ˆ: ì¥¬ì‹œ, ë©œë¡œì§€ì˜¤",
        label_visibility="collapsed"
    )

    submitted = st.form_submit_button("ê²€ìƒ‰", use_container_width=True)

if submitted and keyword_input.strip():

    keywords = [k.strip() for k in keyword_input.split(",") if k.strip()]

    mask = False
    for kw in keywords:
        mask |= _norm_series(df_all["product_name"]).str.contains(kw, case=False)

    result_df = df_all[mask]

    if not result_df.empty:
        st.session_state.selected_products = set(result_df["product_name"].tolist())
    else:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

    st.rerun()



    # -------------------------
    # í‚¤ì›Œë“œë³„ ê²°ê³¼ ì¶œë ¥
    # -------------------------
    st.subheader("ğŸ“¦ ë¹„êµí•  ì œí’ˆ ì„ íƒ")

    if st.session_state.keyword_results:
        all_candidates = []

        for kw in reversed(list(st.session_state.keyword_results.keys())):
            st.markdown(f"#### ğŸ” '{kw}' ê²€ìƒ‰ ê²°ê³¼")

            col_title, col_delete = st.columns([8, 2])
            with col_delete:
                if st.button("ê²€ìƒ‰ ê²°ê³¼ ì‚­ì œ", key=f"del_{kw}"):
                    df_kw = st.session_state.keyword_results[kw]
                    remove_list = df_kw["product_name"].tolist()

                    st.session_state.selected_products = {
                        p for p in st.session_state.selected_products
                        if p not in remove_list
                    }

                    del st.session_state.keyword_results[kw]
                    st.rerun()

            df_kw = st.session_state.keyword_results[kw]
            product_list = sorted(df_kw["product_name"].unique().tolist())

            for pname in product_list:
                st.checkbox(
                    pname,
                    value=pname in st.session_state.selected_products,
                    key=f"chk_{kw}_{pname}",
                    on_change=toggle_product,
                    args=(pname,),
                )

            all_candidates.append(df_kw)

        candidates_df = pd.concat(all_candidates).drop_duplicates()

    else:
        st.info("ì œí’ˆëª… í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        candidates_df = pd.DataFrame()

# --- B) í•„í„° ì„ íƒ ---
else:
    col1, col2, col3 = st.columns(3)

    with col1:
        brands = options_from(df_all, "brand")
        sel_brand = st.selectbox("ë¸Œëœë“œ", ["(ì „ì²´)"] + brands)

    df1 = df_all if sel_brand == "(ì „ì²´)" else df_all[df_all["brand"] == sel_brand]

    with col2:
        cat1s = options_from(df1, "category1")
        sel_cat1 = st.selectbox("ì¹´í…Œê³ ë¦¬1", ["(ì „ì²´)"] + cat1s)

    df2 = df1 if sel_cat1 == "(ì „ì²´)" else df1[df1["category1"] == sel_cat1]

    with col3:
        cat2s = options_from(df2, "category2")
        sel_cat2 = st.selectbox("ì¹´í…Œê³ ë¦¬2", ["(ì „ì²´)"] + cat2s)

    candidates_df = df2 if sel_cat2 == "(ì „ì²´)" else df2[df2["category2"] == sel_cat2]

# í•„í„° ê²°ê³¼ì—ì„œ ì œí’ˆ ì„ íƒ
if search_mode == "í•„í„° ì„ íƒ (ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬)":
    st.subheader("ğŸ“¦ ë¹„êµí•  ì œí’ˆ ì„ íƒ")

    with st.expander("ëª©ë¡ í¼ì¹˜ê¸° / ì ‘ê¸°", expanded=False):
        product_list = sorted(candidates_df["product_name"].unique().tolist())

        for pname in product_list:
            st.checkbox(
                pname,
                value=pname in st.session_state.selected_products,
                key=f"chk_filter_{pname}",
                on_change=toggle_product,
                args=(pname,),
            )

# =========================
# 8ï¸âƒ£ ê²°ê³¼ í‘œì‹œ
# =========================
selected_products = list(st.session_state.selected_products)

if not selected_products:
    st.info("ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.")
    st.stop()

if not st.session_state.show_results:
    st.info("ì œí’ˆì„ ì„ íƒí•œ ë’¤ â€˜ì¡°íšŒí•˜ê¸°â€™ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
    st.stop()

st.divider()
st.subheader(f"ğŸ“Š ì¡°íšŒ ê²°ê³¼ ({len(selected_products)}ê°œ ì œí’ˆ)")

timeline_rows = []
lifecycle_rows = []

for pname in selected_products:
    row = df_all[df_all["product_name"] == pname].iloc[0]

    # ê°€ê²© ì´ë²¤íŠ¸
    df_price = load_events(row["product_url"])
    if not df_price.empty:
        tmp = df_price.copy()
        tmp["product_name"] = pname
        tmp["event_date"] = pd.to_datetime(tmp["date"])
        tmp["unit_price"] = tmp["unit_price"].astype(float)
        
        # ğŸ”¥ lifecycle ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        df_life = load_lifecycle_events(row["product_url"])
        
        if not df_life.empty:
            df_life["date"] = pd.to_datetime(df_life["date"])
        
            # í’ˆì ˆ/ë³µì› êµ¬ê°„ ê³„ì‚°
            out_dates = df_life[df_life["lifecycle_event"] == "OUT_OF_STOCK"]["date"].tolist()
            restore_dates = df_life[df_life["lifecycle_event"] == "RESTOCK"]["date"].tolist()
        
            for out_date in out_dates:
                # í•´ë‹¹ í’ˆì ˆ ì´í›„ ì²« ë³µì› ë‚ ì§œ ì°¾ê¸°
                restore_after = [d for d in restore_dates if d > out_date]
                if restore_after:
                    restore_date = min(restore_after)
        
                    # ğŸ”¥ í’ˆì ˆ~ë³µì› ì‚¬ì´ ê°€ê²© ì œê±°
                    mask = (tmp["event_date"] > out_date) & (tmp["event_date"] < restore_date)
                    tmp.loc[mask, "unit_price"] = None
        
        timeline_rows.append(tmp[["product_name", "event_date", "unit_price"]])
        

    # lifecycle ì´ë²¤íŠ¸
    df_life = load_lifecycle_events(row["product_url"])
    if not df_life.empty:
        tmp2 = df_life.copy()
        tmp2["product_name"] = pname
        tmp2["event_date"] = pd.to_datetime(tmp2["date"])
        lifecycle_rows.append(tmp2[["product_name", "event_date", "lifecycle_event"]])

# =========================
# 8-1ï¸âƒ£ ê°œë‹¹ ê°€ê²© íƒ€ì„ë¼ì¸ ë¹„êµ ì°¨íŠ¸
# =========================
if timeline_rows:

    df_timeline = pd.concat(timeline_rows, ignore_index=True)

    # 1ï¸âƒ£ ì •ë ¬ (í•„ìˆ˜)
    df_timeline = df_timeline.sort_values(
        ["product_name", "event_date"]
    )

    # 2ï¸âƒ£ ìˆ«ì ê°•ì œ ë³€í™˜
    df_timeline["unit_price"] = pd.to_numeric(
        df_timeline["unit_price"], errors="coerce"
    )

    # 3ï¸âƒ£ segment ì»¬ëŸ¼ ìƒì„± (ëŠê¹€ ì™„ì „ ë¶„ë¦¬ìš©)
    df_timeline["segment"] = (
        df_timeline["unit_price"].isna()
        .groupby(df_timeline["product_name"])
        .cumsum()
    )

    # 4ï¸âƒ£ NaN ì œê±° (ëŠê¸´ êµ¬ê°„ì€ ì°¨íŠ¸ì—ì„œ ì œì™¸)
    df_chart = df_timeline.dropna(subset=["unit_price"])

    # =========================
    # ğŸ“ˆ ê°€ê²© ì„  ì°¨íŠ¸
    # =========================
    base_line = (
        alt.Chart(df_chart)
        .mark_line(point=True)
        .encode(
            x=alt.X("event_date:T", title="ë‚ ì§œ"),
            y=alt.Y("unit_price:Q", title="ê°œë‹¹ ê°€ê²© (ì›)"),
            color=alt.Color("product_name:N", title="ì œí’ˆ"),
            detail="segment:N",  # ğŸ”¥ ì´ê²Œ í•µì‹¬ (ì„  ì™„ì „ ë¶„ë¦¬)
            tooltip=[
                alt.Tooltip("product_name:N", title="ì œí’ˆ"),
                alt.Tooltip("event_date:T", title="ë‚ ì§œ"),
                alt.Tooltip("unit_price:Q", title="ê°œë‹¹ ê°€ê²©", format=",.1f"),
            ],
        )
    )

    layers = [base_line]

    # =========================
    # ğŸ”” Lifecycle ì•„ì´ì½˜ ì¶”ê°€
    # =========================
    if lifecycle_rows:

        df_life_all = pd.concat(lifecycle_rows, ignore_index=True)

        icon_config = {
            "NEW_PRODUCT": {"color": "green", "label": "NEW"},
            "OUT_OF_STOCK": {"color": "red", "label": "í’ˆì ˆ"},
            "RESTOCK": {"color": "orange", "label": "ë³µì›"},
        }

        for event_type, cfg in icon_config.items():

            df_filtered = df_life_all[
                df_life_all["lifecycle_event"] == event_type
            ]

            if df_filtered.empty:
                continue

            # ì•„ì´ì½˜ ìœ„ì¹˜ë¥¼ ê°€ê²©ì„ ì— ë§ì¶”ê¸° ìœ„í•´ join
            df_filtered = df_filtered.merge(
                df_timeline[["product_name", "event_date", "unit_price"]],
                on=["product_name", "event_date"],
                how="left"
            )
            
            # (ì„ íƒ) ë””ë²„ê¹…ìš© â€” í•„ìš”í•  ë•Œë§Œ
            # if st.checkbox("ë””ë²„ê·¸: lifecycle merge ë³´ê¸°"):
            #     st.dataframe(df_filtered[["product_name","event_date","unit_price"]])
            
            # ğŸ”¥ ì¤‘ìš”: unit_price ì—†ëŠ” lifecycle ì œê±° (ê°€ê²©ì„ ì— ì •í™•íˆ ë¶™ì´ê¸° ìœ„í•¨)
            df_filtered = df_filtered.dropna(subset=["unit_price"])

            

            point_layer = (
               alt.Chart(df_filtered)
                .mark_point(
                    size=150,
                    shape="triangle-up",
                    color=cfg["color"]
                )
                .encode(
                    x="event_date:T",
                    y="unit_price:Q",   # ğŸ”¥ ë°˜ë“œì‹œ ì¶”ê°€
                    tooltip=[
                        alt.Tooltip("product_name:N", title="ì œí’ˆ"),
                        alt.Tooltip("event_date:T", title="ë‚ ì§œ"),
                        alt.Tooltip("lifecycle_event:N", title="ì´ë²¤íŠ¸"),
                    ],
                )
            )

            text_layer = (
                alt.Chart(df_filtered)
                .mark_text(
                    dy=12,   # ğŸ”¥ ì•„ë˜ë¡œ 12px ì´ë™
                    fontSize=11,
                    fontWeight="bold",
                    color=cfg["color"]
                )
                .encode(
                    x="event_date:T",
                    y="unit_price:Q",   # ğŸ”¥ ë°˜ë“œì‹œ ë™ì¼í•˜ê²Œ
                    text=alt.value(cfg["label"]),
                )
            )


            layers.append(point_layer)
            layers.append(text_layer)

    chart = (
        alt.layer(*layers)
        .properties(height=420)
        .interactive()
    )

    st.altair_chart(chart, use_container_width=True)

else:
    st.info("ë¹„êµ ê°€ëŠ¥í•œ ì´ë²¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


st.divider()

# =========================
# 8-2ï¸âƒ£ ì œí’ˆë³„ ì¹´ë“œ
# =========================
for pname in selected_products:
    p = df_all[df_all["product_name"] == pname].iloc[0]
    st.markdown(f"### {p['product_name']}")

    c1, c2, c3, c4 = st.columns(4)

    with c1:
        st.metric("ê°œë‹¹ ê°€ê²©", f"{float(p['current_unit_price']):,.1f}ì›")


    with c2:
    
        # ğŸ”¥ í˜„ì¬ ì„ íƒëœ ê¸°ê°„ ê°€ì ¸ì˜¤ê¸°
        date_from = df_timeline["event_date"].min().date()
        date_to = df_timeline["event_date"].max().date()
    
        res = supabase.rpc(
            "get_discount_periods_in_range",
            {
                "p_product_url": p["product_url"],
                "p_date_from": str(date_from),
                "p_date_to": str(date_to),
            }
        ).execute()
    
        discount_rows = res.data if res.data else []
    
        if discount_rows:
    
            for d in discount_rows:
                st.success(
                    f"ğŸ’¸ í• ì¸ {d['discount_start_date']} ~ {d['discount_end_date']}"
                )
    
        else:
            st.info("ì •ìƒê°€")


    with c3:
        df_life = load_lifecycle_events(p["product_url"])
        has_new = (not df_life.empty) and (df_life["lifecycle_event"] == "NEW_PRODUCT").any()
        if has_new:
            st.warning("ğŸ†• ì‹ ì œí’ˆ")
        else:
            st.caption(f"ê´€ì¸¡ ì‹œì‘ì¼\n{p['first_seen_date']}")

    with c4:
        st.caption(f"ë§ˆì§€ë§‰ ê´€ì¸¡ì¼\n{p['last_seen_date']}")

    if p["product_event_status"] == "NO_EVENT_STABLE":
        st.info("ğŸ“Š ê°€ê²© ë³€ë™ ì—†ìŒ")
    else:
        st.success(f"ğŸ“ˆ ê°€ê²© ì´ë²¤íŠ¸ {p['event_count']}ê±´")

    with st.expander("ğŸ“… ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬"):
        df_price = load_events(p["product_url"])
        df_life = load_lifecycle_events(p["product_url"])

        frames = []

        # 1) ê°€ê²© ì´ë²¤íŠ¸ ì •ì œ
        if not df_price.empty:
            df_price = df_price.copy()
            df_price["date"] = pd.to_datetime(df_price["date"])
            df_price = df_price[df_price["event_type"] != "NORMAL"]
            if not df_price.empty:
                frames.append(df_price[["date", "unit_price", "event_type"]])

        # 2) Lifecycle ì´ë²¤íŠ¸
        if not df_life.empty:
            df_life = df_life[df_life["lifecycle_event"].notna()]
            df_life = df_life.rename(columns={"lifecycle_event": "event_type"})
            df_life["unit_price"] = None
            df_life["date"] = pd.to_datetime(df_life["date"])
            frames.append(df_life[["date", "unit_price", "event_type"]])

        if not frames:
            st.caption("ì´ë²¤íŠ¸ ì—†ìŒ")
            continue

        df_all_events = pd.concat(frames, ignore_index=True)
        df_all_events = df_all_events.drop_duplicates(subset=["date", "event_type"])

        # 4) í• ì¸ êµ¬ê°„ ë¬¶ê¸°
        if not df_price.empty:
            df_discount = df_price[df_price["event_type"] == "DISCOUNT"]
            if not df_discount.empty:
                df_discount = df_discount.sort_values("date")
                df_discount["gap"] = df_discount["date"].diff().dt.days.fillna(1)
                df_discount["group"] = (df_discount["gap"] > 1).cumsum()

                discount_periods = (
                    df_discount.groupby("group")
                    .agg(
                        start_date=("date", "min"),
                        end_date=("date", "max"),
                        unit_price=("unit_price", "first")
                    )
                    .reset_index(drop=True)
                )
            else:
                discount_periods = pd.DataFrame()
        else:
            discount_periods = pd.DataFrame()

        display_rows = []

        for _, row_d in discount_periods.iterrows():
            display_rows.append({
                "ë‚ ì§œ": f"{row_d['start_date'].date()} ~ {row_d['end_date'].date()}",
                "ê°œë‹¹ ê°€ê²©": round(float(row_d["unit_price"]), 1) if pd.notna(row_d["unit_price"]) else None,
                "ì´ë²¤íŠ¸": "ğŸ’¸ í• ì¸ ê¸°ê°„"
            })

        icon_map = {
            "NEW_PRODUCT": "ğŸ†• ì‹ ì œí’ˆ",
            "OUT_OF_STOCK": "âŒ í’ˆì ˆ",
            "RESTOCK": "ğŸ”„ ë³µì›",
        }

        df_lifecycle_only = df_all_events[df_all_events["event_type"].isin(icon_map.keys())]
        for _, row_l in df_lifecycle_only.iterrows():
            display_rows.append({
                "ë‚ ì§œ": row_l["date"].date(),
                "ê°œë‹¹ ê°€ê²©": None,
                "ì´ë²¤íŠ¸": icon_map.get(row_l["event_type"], row_l["event_type"])
            })

        if not display_rows:
            st.caption("ì‹¤ì œ ë³€í™” ì´ë²¤íŠ¸ ì—†ìŒ")
            continue

        df_display = pd.DataFrame(display_rows)
        df_display = df_display.sort_values("ë‚ ì§œ", ascending=False)

        st.dataframe(
            df_display.style.format({"ê°œë‹¹ ê°€ê²©": "{:.1f}"}),
            use_container_width=True,
            hide_index=True
        )

# =========================
# 9ï¸âƒ£ ìì—°ì–´ ì§ˆë¬¸ (Rule â†’ LLM fallback)
# =========================
st.divider()
st.subheader("ğŸ¤– ê°€ê²© ì¸ì‚¬ì´íŠ¸ ì§ˆë¬¸")

question = st.text_input(
    "ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”",
    placeholder="ì˜ˆ: ì—ìŠ¤í”„ë ˆì†Œ ì¤‘ ìµœì €ê°€ / ìµœê·¼ 3ê°œì›” ë³€ë™í­ í° ì œí’ˆ",
)

def classify_intent(q: str):
    q = q.lower()

    if "í• ì¸" in q or "í–‰ì‚¬" in q:
        return "DISCOUNT"
    if any(word in q for word in ["ì‹ ì œí’ˆ", "ìƒˆë¡­ê²Œ", "ìƒˆë¡œ", "ì‹ ê·œ", "ì¶œì‹œ", "ìƒˆë¡œìš´", "ì²˜ìŒ"]):
        return "NEW"
    if "ê°€ì¥ ì‹¼" in q or "ìµœì €ê°€" in q:
        return "PRICE_MIN"
    if "ë¹„ì‹¼" in q or "ìµœê³ ê°€" in q:
        return "PRICE_MAX"
    if any(word in q for word in ["ìƒìŠ¹", "ì¦ê°€"]) and "ì•Š" not in q:
        return "PRICE_UP"
    if "ë³€ë™" in q or "ë§ì´ ë°”ë€" in q:
        return "VOLATILITY"
    if "í’ˆì ˆ" in q:
        return "OUT"
    if "ë³µì›" in q:
        return "RESTORE"
    if "ì •ìƒê°€" in q and "ë³€ë™" in q:
        return "NORMAL_CHANGE"

    return "UNKNOWN"

def extract_period(q: str):
    today = datetime.today()

    if any(word in q for word in ["ìµœê·¼ 7ì¼", "ìµœê·¼ ì¼ì£¼ì¼", "ìµœê·¼ 1ì£¼ì¼"]):
        return today - timedelta(days=7)
    if any(word in q for word in ["ìµœê·¼ í•œ ë‹¬", "ìµœê·¼ 30ì¼", "ìµœê·¼ 1ê°œì›”"]):
        return today - timedelta(days=30)
    if "ìµœê·¼ 3ê°œì›”" in q:
        return today - timedelta(days=90)
    if "ìµœê·¼ 1ë…„" in q:
        return today - timedelta(days=365)

    return None

def extract_brew_type(q: str, df_all: pd.DataFrame):
    q = q.lower()
    brew_list = df_all["brew_type_kr"].dropna().unique().tolist()

    for brew in brew_list:
        if brew and brew.lower() in q:
            return brew
    return None

def execute_rule(intent, question, df_summary):
    df_work = df_summary.copy()

    brew_condition = extract_brew_type(question, df_summary)
    if brew_condition:
        df_work = df_work[df_work["brew_type_kr"] == brew_condition]

    start_date = extract_period(question)

    if intent == "DISCOUNT" and not start_date:
        df = df_work[df_work["is_discount"] == True]
        if df.empty:
            return None
        return "í˜„ì¬ í• ì¸ ì¤‘ ì œí’ˆ:\n- " + "\n- ".join(df["product_name"].tolist())

    if intent == "PRICE_MIN":
        df_valid = df_work[df_work["current_unit_price"] > 0]
        if df_valid.empty:
            return "í˜„ì¬ íŒë§¤ ì¤‘ì¸ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."

        min_price = df_valid["current_unit_price"].min()
        df_min = df_valid[df_valid["current_unit_price"] == min_price]

        output_lines = []
        for _, row in df_min.iterrows():
            res = (
                supabase.table("product_all_events")
                .select("date, unit_price")
                .eq("product_url", row["product_url"])
                .execute()
            )
            if not res.data:
                continue

            df_hist = pd.DataFrame(res.data)
            df_hist["date"] = pd.to_datetime(df_hist["date"])
            df_hist["unit_price"] = df_hist["unit_price"].astype(float)
            df_hist = df_hist[df_hist["unit_price"] > 0]

            df_low = df_hist[df_hist["unit_price"] == min_price]
            if df_low.empty:
                continue

            sd = df_low["date"].min().date()
            ed = df_low["date"].max().date()
            output_lines.append(
                f"- {row['product_name']} / {min_price:,.1f}ì›\n"
                f"  ìµœì €ê°€ ê¸°ê°„: {sd} ~ {ed}"
            )

        if not output_lines:
            return "ìµœì €ê°€ ê³„ì‚° ëŒ€ìƒ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."

        return "ìµœì €ê°€ ì œí’ˆ ëª©ë¡:\n\n" + "\n\n".join(output_lines)

    if intent == "PRICE_MAX":
        df = df_work[df_work["current_unit_price"] > 0].sort_values("current_unit_price", ascending=False)
        if df.empty:
            return None
        top = df.iloc[0]
        return f"ê°€ì¥ ë¹„ì‹¼ ì œí’ˆì€ '{top['product_name']}'ì´ë©° {float(top['current_unit_price']):,.1f}ì›ì…ë‹ˆë‹¤."

    if intent == "NEW":
        res = (
            supabase.table("product_lifecycle_events")
            .select("product_url")
            .eq("lifecycle_event", "NEW_PRODUCT")
            .execute()
        )
        if not res.data:
            return None
        urls = [r["product_url"] for r in res.data]
        df = df_work[df_work["product_url"].isin(urls)]
        if df.empty:
            return None
        return "ìµœê·¼ ì‹ ì œí’ˆ:\n- " + "\n- ".join(df["product_name"].tolist())

    if intent == "OUT":
        res = (
            supabase.table("product_lifecycle_events")
            .select("product_url")
            .eq("lifecycle_event", "OUT_OF_STOCK")
            .execute()
        )
        if not res.data:
            return None
        urls = [r["product_url"] for r in res.data]
        df = df_work[df_work["product_url"].isin(urls)]
        if df.empty:
            return None
        return "ìµœê·¼ í’ˆì ˆ ì œí’ˆ:\n- " + "\n- ".join(df["product_name"].tolist())

    if intent == "RESTORE":
        res = (
            supabase.table("product_lifecycle_events")
            .select("product_url")
            .eq("lifecycle_event", "RESTOCK")
            .execute()
        )
        if not res.data:
            return None
        urls = [r["product_url"] for r in res.data]
        df = df_work[df_work["product_url"].isin(urls)]
        if df.empty:
            return None
        return "ìµœê·¼ ë³µì›ëœ ì œí’ˆ:\n- " + "\n- ".join(df["product_name"].tolist())

    if intent == "VOLATILITY" and start_date:
        res = (
            supabase.table("product_all_events")
            .select("product_url, unit_price, date")
            .gte("date", start_date.strftime("%Y-%m-%d"))
            .execute()
        )
        if not res.data:
            return None

        df = pd.DataFrame(res.data)
        df["unit_price"] = df["unit_price"].astype(float)

        volatility = (
            df.groupby("product_url")["unit_price"]
            .agg(lambda x: x.max() - x.min())
            .sort_values(ascending=False)
        )

        if volatility.empty:
            return None

        top_url = volatility.index[0]
        top_value = volatility.iloc[0]

        row = df_work[df_work["product_url"] == top_url]
        if row.empty:
            return None

        return (
            f"ìµœê·¼ ê¸°ê°„ ê°€ê²© ë³€ë™ í­ì´ ê°€ì¥ í° ì œí’ˆì€ "
            f"'{row.iloc[0]['product_name']}'ì´ë©° "
            f"ë³€ë™í­ì€ {top_value:,.1f}ì›ì…ë‹ˆë‹¤."
        )

    if intent == "NORMAL_CHANGE":
        start_date = extract_period(question)

        query = supabase.table("product_normal_price_events").select("*")
        if start_date:
            query = query.gte("date", start_date.strftime("%Y-%m-%d"))

        res = query.order("date", desc=True).execute()
        if not res.data:
            return "í•´ë‹¹ ê¸°ê°„ ë‚´ ì •ìƒê°€ ë³€ë™ì´ ì—†ìŠµë‹ˆë‹¤."

        df = pd.DataFrame(res.data)
        results = []

        for _, row in df.iterrows():
            product_row = df_summary[df_summary["product_url"] == row["product_url"]]
            if product_row.empty:
                continue

            pname = product_row.iloc[0]["product_name"]
            results.append(
                f"- {pname} / {float(row['prev_price']):,.0f}ì› â†’ "
                f"{row['date']}ì— {float(row['normal_price']):,.0f}ì› "
                f"({float(row['price_diff']):+,.0f}ì›)"
            )

        return "ê¸°ê°„ ë‚´ ì •ìƒê°€ ë³€ë™ ì œí’ˆ ëª©ë¡:\n" + "\n".join(results) if results else "í•´ë‹¹ ê¸°ê°„ ë‚´ ì •ìƒê°€ ë³€ë™ì´ ì—†ìŠµë‹ˆë‹¤."

    return None

def llm_fallback(question: str, df_summary: pd.DataFrame):
    context = df_summary.head(50)[
        ["product_name", "current_unit_price", "is_discount", "is_new_product", "brew_type_kr"]
    ].to_dict(orient="records")

    prompt = f"""
ë‹¹ì‹ ì€ ì»¤í”¼ ìº¡ìŠ ê°€ê²© ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

ë°ì´í„°:
{context}

ì§ˆë¬¸:
{question}
"""

    from openai import OpenAI
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )

    return response.choices[0].message.content

if question:
    intent = classify_intent(question)
    answer = execute_rule(intent, question, df_all)

    if answer:
        save_question_log(question, intent, False)
        st.success(answer)
    else:
        with st.spinner("ë¶„ì„ ì¤‘..."):
            answer = llm_fallback(question, df_all)
        save_question_log(question, intent, True)
        st.success(answer)








